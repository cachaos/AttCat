{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d90a11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "from scipy.special import softmax\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from captum.attr import visualization\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from BERT_explainability.modules.BERT.BertForSequenceClassification import BertForSequenceClassification\n",
    "\n",
    "\n",
    "###mods\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a936fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric \n",
    "from datasets import list_datasets, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0661e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model   \n",
    "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-QQP\").to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-QQP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862a1873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "649e4409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (add1): Add()\n",
       "      (add2): Add()\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (matmul1): MatMul()\n",
       "              (matmul2): MatMul()\n",
       "              (softmax): Softmax(dim=-1)\n",
       "              (add): Add()\n",
       "              (mul): Mul()\n",
       "              (clone): Clone()\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (add): Add()\n",
       "            )\n",
       "            (clone): Clone()\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELU(approximate='none')\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (add): Add()\n",
       "          )\n",
       "          (clone): Clone()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "      (pool): IndexSelect()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bee2e360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/anwbw/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bdc49ea6cfd48e6a5627d5dc4707745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = \"glue\"\n",
    "task = \"qqp\" # select a task\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "special_tokens = {101,102}    \n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "qqp = load_dataset(dataset, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09acb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, padding=False, max_length=tokenizer.model_max_length, truncation=True)\n",
    "    \n",
    "       # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if \"label\" in examples:\n",
    "        result[\"label\"] = examples[\"label\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1950a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-9a82dfe93f3221b3.arrow\n",
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/qqp/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-1aa5f42ca3e0c430.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/390965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_qqp = qqp.map(preprocess_function, batched=True, remove_columns=qqp[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c948ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {101,102}    \n",
    "mask = \"[PAD]\"\n",
    "mask_id = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b81974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(tokenized_qqp,index):\n",
    "    input_ids = tokenized_qqp['validation'][index]['input_ids']\n",
    "    text_ids = (torch.tensor([input_ids])).to(\"cuda\")\n",
    "    text_words = tokenizer.convert_ids_to_tokens(text_ids[0])\n",
    "    \n",
    "    att_mask = tokenized_qqp['validation'][index]['attention_mask']\n",
    "    special_idxs = [x for x, y in list(enumerate(input_ids)) if y in special_tokens]\n",
    "    att_mask = [0 if index in special_idxs else 1 for index, item in enumerate(att_mask)]\n",
    "    att_mask = (torch.tensor([att_mask])).to(\"cuda\")\n",
    "    label = tokenized_qqp['validation'][index]['label']\n",
    "    \n",
    "    return text_ids, att_mask, text_words, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0511511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_instance(instance):\n",
    "    input_ids = instance['input_ids']\n",
    "    text_ids = (torch.tensor([input_ids])).to(\"cuda\")\n",
    "    text_words = tokenizer.convert_ids_to_tokens(text_ids[0])\n",
    "    \n",
    "    att_mask = instance['attention_mask']\n",
    "    special_idxs = [x for x, y in list(enumerate(input_ids)) if y in special_tokens]\n",
    "    att_mask = [0 if index in special_idxs else 1 for index, item in enumerate(att_mask)]\n",
    "    att_mask = (torch.tensor([att_mask])).to(\"cuda\")\n",
    "    label = instance['label']\n",
    "    \n",
    "    return text_ids, att_mask, text_words, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb4c203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rollout between attention layers\n",
    "def compute_rollout_attention(all_layer_matrices, start_layer=0):\n",
    "    \n",
    "    # adding residual consideration- code adapted from https://github.com/samiraabnar/attention_flow\n",
    "    num_tokens = all_layer_matrices[0].shape[1]\n",
    "    batch_size = all_layer_matrices[0].shape[0]\n",
    "    eye = torch.eye(num_tokens).expand(batch_size, num_tokens, num_tokens).to(all_layer_matrices[0].device)\n",
    "    all_layer_matrices = [all_layer_matrices[i] + eye for i in range(len(all_layer_matrices))]\n",
    "    matrices_aug = [all_layer_matrices[i] / all_layer_matrices[i].sum(dim=-1, keepdim=True)\n",
    "                          for i in range(len(all_layer_matrices))]\n",
    "    joint_attention = matrices_aug[start_layer]\n",
    "    for i in range(start_layer+1, len(matrices_aug)):\n",
    "        joint_attention = matrices_aug[i].bmm(joint_attention)\n",
    "        \n",
    "    return joint_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66061f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "\n",
    "    \n",
    "    ###TransCAM seems to be AttCAT - Cat * attentionwheights\n",
    "    def generate_TransCAM(self, input_ids, attention_mask,\n",
    "                          index=None, start_layer=0):\n",
    "\n",
    "        result = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        \n",
    "        output = result[0]\n",
    "        hs = result[1]\n",
    "\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "\n",
    "        for blk_id in range(len(blocks)):\n",
    "            hs[blk_id].retain_grad()\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cams = {}\n",
    "        for blk_id in range(len(blocks)):\n",
    "            hs_grads = hs[blk_id].grad\n",
    "            \n",
    "            att = blocks[blk_id].attention.self.get_attn().squeeze(0)\n",
    "            att = att.mean(dim=0)\n",
    "            att = att.mean(dim=0)\n",
    "            \n",
    "            cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
    "            cat = cat * att\n",
    "            cams[blk_id] = cat\n",
    "            \n",
    "        trans_expln = sum(cams.values())\n",
    "        trans_expln = torch.abs(trans_expln)\n",
    "\n",
    "        return trans_expln\n",
    "\n",
    "    def generate_LRP(self, input_ids, attention_mask,\n",
    "                     index=None, start_layer=11):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cams = []\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "        for blk in blocks:\n",
    "            grad = blk.attention.self.get_attn_gradients()\n",
    "            cam = blk.attention.self.get_attn_cam()\n",
    "            cam = cam[0].reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "            grad = grad[0].reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "            cam = grad * cam\n",
    "            cam = cam.clamp(min=0).mean(dim=0)\n",
    "            cams.append(cam.unsqueeze(0))\n",
    "        rollout = compute_rollout_attention(cams, start_layer=start_layer)\n",
    "        rollout[:, 0, 0] = 0\n",
    "        return rollout[:, 0]\n",
    "\n",
    "\n",
    "    def generate_LRP_last_layer(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn_cam()[0]\n",
    "        cam = cam.clamp(min=0).mean(dim=0).unsqueeze(0)\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]\n",
    "\n",
    "    def generate_full_lrp(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        cam = self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "        cam = cam.sum(dim=2)\n",
    "        cam[:, 0] = 0\n",
    "        return cam\n",
    "\n",
    "    def generate_attn_last_layer(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn()[0]\n",
    "        cam = cam.mean(dim=0).unsqueeze(0)\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]\n",
    "\n",
    "    def generate_rollout(self, input_ids, attention_mask, start_layer=0, index=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "        all_layer_attentions = []\n",
    "        for blk in blocks:\n",
    "            attn_heads = blk.attention.self.get_attn()\n",
    "            avg_heads = (attn_heads.sum(dim=1) / attn_heads.shape[1]).detach()\n",
    "            all_layer_attentions.append(avg_heads)\n",
    "        rollout = compute_rollout_attention(all_layer_attentions, start_layer=start_layer)\n",
    "        rollout[:, 0, 0] = 0\n",
    "        return rollout[:, 0]\n",
    "\n",
    "    def generate_attn_gradcam(self, input_ids, attention_mask, index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn()\n",
    "        grad = self.model.bert.encoder.layer[-1].attention.self.get_attn_gradients()\n",
    "\n",
    "        cam = cam[0].reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "        grad = grad[0].reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "        grad = grad.mean(dim=[1, 2], keepdim=True)\n",
    "        cam = (cam * grad).mean(0).clamp(min=0).unsqueeze(0)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "584744a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explns(explanations, input_ids, attention_mask, start_layer=0, true_class = 1, is_true = True):\n",
    "    \n",
    "    if is_true:\n",
    "        # TransCAM\n",
    "        TransCAM_expln = explanations.generate_TransCAM(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)\n",
    "        # LRP\n",
    "        LRP_expln = explanations.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)[0]\n",
    "        # PartialLRP\n",
    "        PartialLRP_expln = explanations.generate_LRP_last_layer(input_ids=input_ids, \n",
    "                                                     index=true_class, attention_mask=attention_mask)[0]\n",
    "        # FullLRP\n",
    "        # FullLRP_expln = explanations.generate_full_lrp(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                           index=true_class)[0]\n",
    "        # Att\n",
    "        Att_expln = explanations.generate_attn_last_layer(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class)[0]\n",
    "        # Rollout\n",
    "        Rollout_expln = explanations.generate_rollout(input_ids=input_ids, attention_mask=attention_mask,      \n",
    "                                                    index=true_class, start_layer=0)[0]\n",
    "        # Att_Gradcam\n",
    "        # Att_Gradcam_expln = explanations.generate_attn_gradcam(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]    \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        true_class = 1-true_class\n",
    "        \n",
    "        # TransCAM\n",
    "        TransCAM_expln = explanations.generate_TransCAM(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)\n",
    "        # LRP\n",
    "        LRP_expln = explanations.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)[0]\n",
    "        # PartialLRP\n",
    "        PartialLRP_expln = explanations.generate_LRP_last_layer(input_ids=input_ids, \n",
    "                                                    index=true_class, attention_mask=attention_mask)[0]\n",
    "        # FullLRP\n",
    "        # FullLRP_expln = explanations.generate_full_lrp(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]\n",
    "        # Att\n",
    "        Att_expln = explanations.generate_attn_last_layer(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class)[0]\n",
    "        # Rollout\n",
    "        Rollout_expln = explanations.generate_rollout(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=0)[0]\n",
    "        # Att_Gradcam\n",
    "        # Att_Gradcam_expln = explanations.generate_attn_gradcam(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]\n",
    "    \n",
    "    # return TransCAM_expln, LRP_expln, PartialLRP_expln, FullLRP_expln, Att_expln, Rollout_expln, Att_Gradcam_expln\n",
    "    return TransCAM_expln, Att_expln, PartialLRP_expln, Rollout_expln, LRP_expln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acdaa00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text_ids, target, att_mask=None, seg_ids=None):\n",
    "    out = model(text_ids, attention_mask=att_mask, token_type_ids=seg_ids)\n",
    "    prob = out[0]\n",
    "    pred_class = torch.argmax(prob, axis=1).cpu().detach().numpy()\n",
    "    pred_class_prob = softmax(prob.cpu().detach().numpy(), axis=1)\n",
    "    return pred_class[0], pred_class_prob[:, target][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52d40b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_words(sorted_idx, text_words, text_ids, replaced_num, seg_ids=None):\n",
    "    to_be_replaced_idx = []\n",
    "    i= 0\n",
    "    while len(to_be_replaced_idx) < replaced_num and i!=len(text_words)-1:\n",
    "        current_idx = sorted_idx[i]\n",
    "        if text_words[current_idx] not in special_tokens:\n",
    "            to_be_replaced_idx.append(current_idx)\n",
    "        i += 1\n",
    "    remaining_idx = sorted(list(set(sorted_idx) - set(to_be_replaced_idx)))\n",
    "    truncated_text_ids = text_ids[0, np.array(remaining_idx)]\n",
    "    if seg_ids is not None:\n",
    "        seg_ids = seg_ids[0, np.array(remaining_idx)]\n",
    "    truncated_text_words = np.array(text_words)[remaining_idx]\n",
    "    return truncated_text_ids.unsqueeze(0), truncated_text_words, seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c43d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(sorted_idx, text_words, text_ids, replaced_num, mask, mask_id):\n",
    "    to_be_replaced_idx = []\n",
    "    i= 0\n",
    "    while len(to_be_replaced_idx) < replaced_num and i!=len(text_words)-1:\n",
    "        current_idx = sorted_idx[i]\n",
    "        if text_words[current_idx] not in special_tokens:\n",
    "            to_be_replaced_idx.append(current_idx)\n",
    "        i += 1\n",
    "    replaced_text_ids = text_ids.clone()\n",
    "    replaced_text_ids[0, to_be_replaced_idx] = mask_id\n",
    "    replaced_text_words = np.copy(text_words)\n",
    "    replaced_text_words[to_be_replaced_idx] = mask\n",
    "    return replaced_text_ids, replaced_text_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b46b1ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_aopc(original_probs, degradation_probs):\n",
    "    original_probs = np.array(original_probs)\n",
    "    degradation_probs = np.array(degradation_probs)\n",
    "    \n",
    "    diffs = []\n",
    "    for i in range(len(original_probs)):\n",
    "        diffs_k = []\n",
    "        for j in range(9):\n",
    "            diff = original_probs[i] - degradation_probs[i][j]\n",
    "            diffs_k.append(np.abs(diff))\n",
    "        diffs.append(diffs_k)\n",
    "\n",
    "    result = np.mean(diffs, axis=0)\n",
    "    aopc = np.mean(result)\n",
    "    \n",
    "    return aopc\n",
    "\n",
    "def cal_logodds(original_probs, degradation_probs):\n",
    "    original_probs = np.array(original_probs)\n",
    "    degradation_probs = np.array(degradation_probs)\n",
    "    \n",
    "    ratios = []\n",
    "    for i in range(len(original_probs)):\n",
    "        ratios_k = []\n",
    "        for j in range(9):\n",
    "            ratio = math.log(degradation_probs[i][j] / original_probs[i])\n",
    "            ratios_k.append(ratio)\n",
    "        ratios.append(ratios_k)\n",
    "\n",
    "    result = np.mean(ratios, axis=0)\n",
    "    logodds = np.mean(result)\n",
    "    \n",
    "    return logodds\n",
    "\n",
    "def cal_kendaltau(attribution1, attribution2,):\n",
    "\n",
    "    sorted_idx1 = np.argsort(-attribution1)\n",
    "    sorted_idx2 = np.argsort(-attribution2)\n",
    "\n",
    "    tau, p_value = stats.kendalltau(sorted_idx1, sorted_idx2)\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca56d3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, explanations, test_data, degrade_step = 10, seg_ids=None):\n",
    "    \n",
    "    original_probs = []\n",
    "    original_accs = [] \n",
    "    \n",
    "    degradation_probs_TransCAM = []\n",
    "    degradation_accs_TransCAM = []\n",
    "    del_probs_TransCAM = []\n",
    "    del_accs_TransCAM = []\n",
    "    \n",
    "    degradation_probs_Rawatt = []\n",
    "    degradation_accs_Rawatt = []\n",
    "    del_probs_Rawatt = []\n",
    "    del_accs_Rawatt = []\n",
    "    \n",
    "    degradation_probs_PartialLRP = []\n",
    "    degradation_accs_PartialLRP = []\n",
    "    del_probs_PartialLRP = []\n",
    "    del_accs_PartialLRP = []\n",
    "    \n",
    "    degradation_probs_Rollout = []\n",
    "    degradation_accs_Rollout = []\n",
    "    del_probs_Rollout = []\n",
    "    del_accs_Rollout = []\n",
    "    \n",
    "    degradation_probs_LRP = []\n",
    "    degradation_accs_LRP = []\n",
    "    del_probs_LRP = []\n",
    "    del_accs_LRP = []\n",
    "    \n",
    "    kendaltaus_TransCAM = []\n",
    "    kendaltaus_Rawatt = []\n",
    "    kendaltaus_PartialLRP = []\n",
    "    kendaltaus_Rollout = []\n",
    "    kendaltaus_LRP = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, test_instance in enumerate(test_data):\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"testinstant\" + str(i) + \"of\" + str(len(test_data)))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "        text_ids, att_mask, text_words, target = preprocess_instance(test_instance)\n",
    "        \n",
    "        # get truc words number\n",
    "        total_len = len(text_words)\n",
    "        if total_len< 10: \n",
    "            continue\n",
    "        granularity = np.linspace(0, 1, degrade_step)\n",
    "        trunc_words_num = [int(g) for g in np.round(granularity*total_len)]\n",
    "        trunc_words_num = list(dict.fromkeys(trunc_words_num))\n",
    "        \n",
    "        original_class, original_prob = predict(model, text_ids, target)\n",
    "        \n",
    "        # get attributions\n",
    "        attribution_TransCAM, attribution_Rawatt, attribution_PartialLRP, attribution_Rollout, attribution_LRP = \\\n",
    "        generate_explns(explanations, text_ids, att_mask, start_layer=0, true_class = target, is_true = True) \n",
    "        \n",
    "        attribution_TransCAM_F, attribution_Rawatt_F, attribution_PartialLRP_F, attribution_Rollout_F, attribution_LRP_F = \\\n",
    "        generate_explns(explanations, text_ids, att_mask, start_layer=0, true_class = target, is_true = False) \n",
    "        \n",
    "        # conver to cpu numpy\n",
    "        attribution_TransCAM = attribution_TransCAM.cpu().detach().numpy()\n",
    "        attribution_Rawatt = attribution_Rawatt.cpu().detach().numpy()\n",
    "        attribution_PartialLRP = attribution_PartialLRP.cpu().detach().numpy()\n",
    "        attribution_Rollout = attribution_Rollout.cpu().detach().numpy()\n",
    "        attribution_LRP = attribution_LRP.cpu().detach().numpy()\n",
    "        \n",
    "        # conver to cpu numpy\n",
    "        attribution_TransCAM_F = attribution_TransCAM_F.cpu().detach().numpy()\n",
    "        attribution_Rawatt_F = attribution_Rawatt_F.cpu().detach().numpy()\n",
    "        attribution_PartialLRP_F = attribution_PartialLRP_F.cpu().detach().numpy()\n",
    "        attribution_Rollout_F = attribution_Rollout_F.cpu().detach().numpy()\n",
    "        attribution_LRP_F = attribution_LRP_F.cpu().detach().numpy()\n",
    "        \n",
    "        # get sorted_idx\n",
    "        sorted_idx_TransCAM = np.argsort(-attribution_TransCAM)\n",
    "        sorted_idx_Rawatt = np.argsort(-attribution_Rawatt)\n",
    "        sorted_idx_PartialLRP = np.argsort(-attribution_PartialLRP)\n",
    "        sorted_idx_Rollout = np.argsort(-attribution_Rollout)\n",
    "        sorted_idx_LRP = np.argsort(-attribution_LRP)\n",
    "        \n",
    "        instance_degradation_probs_TransCAM = []\n",
    "        instance_degradation_accs_TransCAM = []\n",
    "        instance_replace_probs_TransCAM = []\n",
    "        instance_replace_accs_TransCAM = []\n",
    "        \n",
    "        instance_degradation_probs_Rawatt = []\n",
    "        instance_degradation_accs_Rawatt = []\n",
    "        instance_replace_probs_Rawatt = []\n",
    "        instance_replace_accs_Rawatt = []\n",
    "        \n",
    "        instance_degradation_probs_PartialLRP = []\n",
    "        instance_degradation_accs_PartialLRP = []\n",
    "        instance_replace_probs_PartialLRP = []\n",
    "        instance_replace_accs_PartialLRP = []\n",
    "        \n",
    "        instance_degradation_probs_Rollout = []\n",
    "        instance_degradation_accs_Rollout = []\n",
    "        instance_replace_probs_Rollout = []\n",
    "        instance_replace_accs_Rollout = []\n",
    "        \n",
    "        instance_degradation_probs_LRP = []\n",
    "        instance_degradation_accs_LRP = []\n",
    "        instance_replace_probs_LRP = []\n",
    "        instance_replace_accs_LRP = []\n",
    "\n",
    "        for num in trunc_words_num[1:]: #exclude 0\n",
    "            \n",
    "            # TransCAM\n",
    "            truncated_text_ids_TransCAM, _, _ = truncate_words(sorted_idx_TransCAM, text_words, text_ids, \n",
    "                                                                                        num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_TransCAM, _ = replace_words(sorted_idx_TransCAM, text_words, text_ids, num, mask, mask_id)\n",
    "           \n",
    "            trunc_class_TransCAM, trunc_prob_TransCAM = predict(model, truncated_text_ids_TransCAM, target, seg_ids=seg_ids)\n",
    "            rep_class_TransCAM, rep_prob_TransCAM = predict(model, replaced_text_ids_TransCAM, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_TransCAM.append(trunc_prob_TransCAM)\n",
    "            instance_degradation_accs_TransCAM.append(trunc_class_TransCAM==target)\n",
    "            \n",
    "            instance_replace_probs_TransCAM.append(rep_prob_TransCAM)\n",
    "            instance_replace_accs_TransCAM.append(rep_class_TransCAM==target)\n",
    "            \n",
    "            # Rawatt\n",
    "            truncated_text_ids_Rawatt, _, _ = truncate_words(sorted_idx_Rawatt, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_Rawatt, _ = replace_words(sorted_idx_Rawatt, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            \n",
    "            trunc_class_Rawatt, trunc_prob_Rawatt = predict(model, truncated_text_ids_Rawatt, target, seg_ids=seg_ids)\n",
    "            rep_class_Rawatt, rep_prob_Rawatt = predict(model, replaced_text_ids_Rawatt, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_Rawatt.append(trunc_prob_Rawatt)\n",
    "            instance_degradation_accs_Rawatt.append(trunc_class_Rawatt==target)\n",
    "            \n",
    "            instance_replace_probs_Rawatt.append(rep_prob_Rawatt)\n",
    "            instance_replace_accs_Rawatt.append(rep_class_Rawatt==target)\n",
    "            \n",
    "            # PartialLRP\n",
    "            truncated_text_ids_PartialLRP, _, _ = truncate_words(sorted_idx_PartialLRP, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_PartialLRP, _ = replace_words(sorted_idx_PartialLRP, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            trunc_class_PartialLRP, trunc_prob_PartialLRP = predict(model, truncated_text_ids_PartialLRP, target, seg_ids=seg_ids)\n",
    "            rep_class_PartialLRP, rep_prob_PartialLRP = predict(model, replaced_text_ids_PartialLRP, target, seg_ids=seg_ids)\n",
    "            \n",
    "            instance_degradation_probs_PartialLRP.append(trunc_prob_PartialLRP)\n",
    "            instance_degradation_accs_PartialLRP.append(trunc_class_PartialLRP==target)\n",
    "            \n",
    "            instance_replace_probs_PartialLRP.append(rep_prob_PartialLRP)\n",
    "            instance_replace_accs_PartialLRP.append(rep_class_PartialLRP==target)\n",
    "            \n",
    "            # Rollout\n",
    "            truncated_text_ids_Rollout, _, _ = truncate_words(sorted_idx_Rollout, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_Rollout, _ = replace_words(sorted_idx_Rollout, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            trunc_class_Rollout, trunc_prob_Rollout = predict(model, truncated_text_ids_Rollout, target, seg_ids=seg_ids)\n",
    "            rep_class_Rollout, rep_prob_Rollout = predict(model, replaced_text_ids_Rollout, target, seg_ids=seg_ids)\n",
    "            \n",
    "            instance_degradation_probs_Rollout.append(trunc_prob_Rollout)\n",
    "            instance_degradation_accs_Rollout.append(trunc_class_Rollout==target)\n",
    "            \n",
    "            instance_replace_probs_Rollout.append(rep_prob_Rollout)\n",
    "            instance_replace_accs_Rollout.append(rep_class_Rollout==target)\n",
    "            \n",
    "            # LRP\n",
    "            truncated_text_ids_LRP, _, _ = truncate_words(sorted_idx_LRP, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_LRP, _ = replace_words(sorted_idx_LRP, text_words, text_ids, num, mask, mask_id)\n",
    "                \n",
    "            trunc_class_LRP, trunc_prob_LRP = predict(model, truncated_text_ids_LRP, target, seg_ids=seg_ids)\n",
    "            rep_class_LRP, rep_prob_LRP = predict(model, replaced_text_ids_LRP, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_LRP.append(trunc_prob_LRP)\n",
    "            instance_degradation_accs_LRP.append(trunc_class_LRP==target)\n",
    "            \n",
    "            instance_replace_probs_LRP.append(rep_prob_LRP)\n",
    "            instance_replace_accs_LRP.append(rep_class_LRP==target)\n",
    "\n",
    "        original_probs.append(original_prob)\n",
    "        original_accs.append(original_class==target)\n",
    "        \n",
    "        degradation_probs_TransCAM.append(instance_degradation_probs_TransCAM)\n",
    "        degradation_accs_TransCAM.append(instance_degradation_accs_TransCAM)\n",
    "        del_probs_TransCAM.append(instance_replace_probs_TransCAM)\n",
    "        del_accs_TransCAM.append(instance_replace_accs_TransCAM)\n",
    "        \n",
    "        \n",
    "        degradation_probs_Rawatt.append(instance_degradation_probs_Rawatt)\n",
    "        degradation_accs_Rawatt.append(instance_degradation_accs_Rawatt)\n",
    "        del_probs_Rawatt.append(instance_replace_probs_Rawatt)\n",
    "        del_accs_Rawatt.append(instance_replace_accs_Rawatt)\n",
    "        \n",
    "        degradation_probs_PartialLRP.append(instance_degradation_probs_PartialLRP)\n",
    "        degradation_accs_PartialLRP.append(instance_degradation_accs_PartialLRP)\n",
    "        del_probs_PartialLRP.append(instance_replace_probs_PartialLRP)\n",
    "        del_accs_PartialLRP.append(instance_replace_accs_PartialLRP)\n",
    "        \n",
    "        degradation_probs_Rollout.append(instance_degradation_probs_Rollout)\n",
    "        degradation_accs_Rollout.append(instance_degradation_accs_Rollout)\n",
    "        del_probs_Rollout.append(instance_replace_probs_Rollout)\n",
    "        del_accs_Rollout.append(instance_replace_accs_Rollout)\n",
    "        \n",
    "        degradation_probs_LRP.append(instance_degradation_probs_LRP)\n",
    "        degradation_accs_LRP.append(instance_degradation_accs_LRP)\n",
    "        del_probs_LRP.append(instance_replace_probs_LRP)\n",
    "        del_accs_LRP.append(instance_replace_accs_LRP)\n",
    "        \n",
    "        \n",
    "        kendaltau_TransCAM = cal_kendaltau(attribution_TransCAM,attribution_TransCAM_F)\n",
    "        kendaltaus_TransCAM.append(kendaltau_TransCAM)      \n",
    "        \n",
    "        kendaltau_Rawatt = cal_kendaltau(attribution_Rawatt,attribution_Rawatt_F)\n",
    "        kendaltaus_Rawatt.append(kendaltau_Rawatt)      \n",
    "        \n",
    "        kendaltau_PartialLRP = cal_kendaltau(attribution_PartialLRP,attribution_PartialLRP_F)\n",
    "        kendaltaus_PartialLRP.append(kendaltau_PartialLRP)      \n",
    "        \n",
    "        kendaltau_Rollout = cal_kendaltau(attribution_Rollout,attribution_Rollout_F)\n",
    "        kendaltaus_Rollout.append(kendaltau_Rollout)      \n",
    "        \n",
    "        kendaltau_LRP = cal_kendaltau(attribution_LRP,attribution_LRP_F)\n",
    "        kendaltaus_LRP.append(kendaltau_LRP)      \n",
    "    \n",
    "    # get aopc score\n",
    "    aopc_TransCAM = cal_aopc(original_probs,degradation_probs_TransCAM)\n",
    "    aopc_Rawatt = cal_aopc(original_probs,degradation_probs_Rawatt)\n",
    "    aopc_PartialLRP = cal_aopc(original_probs,degradation_probs_PartialLRP)\n",
    "    aopc_Rollout = cal_aopc(original_probs,degradation_probs_Rollout)\n",
    "    aopc_LRP = cal_aopc(original_probs,degradation_probs_LRP)\n",
    "    \n",
    "    aopc_TransCAM_del = cal_aopc(original_probs,del_probs_TransCAM)\n",
    "    aopc_Rawatt_del = cal_aopc(original_probs,del_probs_Rawatt)\n",
    "    aopc_PartialLRP_del = cal_aopc(original_probs,del_probs_PartialLRP)\n",
    "    aopc_Rollout_del = cal_aopc(original_probs,del_probs_Rollout)\n",
    "    aopc_LRP_del = cal_aopc(original_probs,del_probs_LRP)\n",
    "        \n",
    "        \n",
    "    logodds_TransCAM = cal_logodds(original_probs,degradation_probs_TransCAM)\n",
    "    logodds_Rawatt = cal_logodds(original_probs,degradation_probs_Rawatt)\n",
    "    logodds_PartialLRP = cal_logodds(original_probs,degradation_probs_PartialLRP)\n",
    "    logodds_Rollout = cal_logodds(original_probs,degradation_probs_Rollout)\n",
    "    logodds_LRP = cal_logodds(original_probs,degradation_probs_LRP)\n",
    "    \n",
    "    logodds_TransCAM_del = cal_logodds(original_probs,del_probs_TransCAM)\n",
    "    logodds_Rawatt_del = cal_logodds(original_probs,del_probs_Rawatt)\n",
    "    logodds_PartialLRP_del = cal_logodds(original_probs,del_probs_PartialLRP)\n",
    "    logodds_Rollout_del = cal_logodds(original_probs,del_probs_Rollout)\n",
    "    logodds_LRP_del = cal_logodds(original_probs,del_probs_LRP)\n",
    "        \n",
    "            \n",
    "    # get kendaltau score    \n",
    "    k_TransCAM = np.mean(kendaltaus_TransCAM)\n",
    "    k_Rawatt = np.mean(kendaltaus_Rawatt)\n",
    "    k_PartialLRP = np.mean(kendaltaus_PartialLRP)\n",
    "    k_Rollout = np.mean(kendaltaus_Rollout)\n",
    "    k_LRP = np.mean(kendaltaus_LRP)\n",
    "        \n",
    "    return (aopc_TransCAM, aopc_Rawatt, aopc_PartialLRP, aopc_Rollout, aopc_LRP,\n",
    "            aopc_TransCAM_del, aopc_Rawatt_del, aopc_PartialLRP_del, aopc_Rollout_del, aopc_LRP_del,\n",
    "            k_TransCAM, k_Rawatt, k_PartialLRP, k_Rollout, k_LRP,\n",
    "            logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP,\n",
    "            logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f222dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the explanations generator\n",
    "explanations = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a4a9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_num = 200\n",
    "to_test = np.array(tokenized_qqp['validation'])\n",
    "# to_test_idx = np.random.choice(len(tokenized_qqp['validation']), test_num, replace=False)\n",
    "# to_test = to_test[to_test_idx]\n",
    "# len(to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea202da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testinstant0of40430\n",
      "--- 6.4849853515625e-05 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwbw/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testinstant100of40430\n",
      "--- 204.84743785858154 seconds ---\n",
      "testinstant200of40430\n",
      "--- 409.72242307662964 seconds ---\n",
      "testinstant300of40430\n",
      "--- 615.3391120433807 seconds ---\n",
      "testinstant400of40430\n",
      "--- 819.2570352554321 seconds ---\n",
      "testinstant500of40430\n",
      "--- 1024.3774111270905 seconds ---\n",
      "testinstant600of40430\n",
      "--- 1229.5268347263336 seconds ---\n",
      "testinstant700of40430\n",
      "--- 1433.741144657135 seconds ---\n",
      "testinstant800of40430\n",
      "--- 1640.0258419513702 seconds ---\n",
      "testinstant900of40430\n",
      "--- 1844.9054663181305 seconds ---\n",
      "testinstant1000of40430\n",
      "--- 2050.6600930690765 seconds ---\n",
      "testinstant1100of40430\n",
      "--- 2256.1917946338654 seconds ---\n",
      "testinstant1200of40430\n",
      "--- 2461.644326210022 seconds ---\n",
      "testinstant1300of40430\n",
      "--- 2666.7725672721863 seconds ---\n",
      "testinstant1400of40430\n",
      "--- 2871.638370990753 seconds ---\n",
      "testinstant1500of40430\n",
      "--- 3077.219179391861 seconds ---\n",
      "testinstant1600of40430\n",
      "--- 3282.9500267505646 seconds ---\n",
      "testinstant1700of40430\n",
      "--- 3487.948440551758 seconds ---\n",
      "testinstant1800of40430\n",
      "--- 3695.225373983383 seconds ---\n",
      "testinstant1900of40430\n",
      "--- 3899.844295501709 seconds ---\n",
      "testinstant2000of40430\n",
      "--- 4105.437838554382 seconds ---\n",
      "testinstant2100of40430\n",
      "--- 4310.716137886047 seconds ---\n",
      "testinstant2200of40430\n",
      "--- 4517.277909040451 seconds ---\n",
      "testinstant2300of40430\n",
      "--- 4722.7672827243805 seconds ---\n",
      "testinstant2400of40430\n",
      "--- 4928.63415312767 seconds ---\n",
      "testinstant2500of40430\n",
      "--- 5134.310462236404 seconds ---\n",
      "testinstant2600of40430\n",
      "--- 5342.100541114807 seconds ---\n",
      "testinstant2700of40430\n",
      "--- 5548.473028659821 seconds ---\n",
      "testinstant2800of40430\n",
      "--- 5753.574458360672 seconds ---\n",
      "testinstant2900of40430\n",
      "--- 5958.891431570053 seconds ---\n",
      "testinstant3000of40430\n",
      "--- 6165.588311433792 seconds ---\n",
      "testinstant3100of40430\n",
      "--- 6371.657073020935 seconds ---\n",
      "testinstant3200of40430\n",
      "--- 6578.596258878708 seconds ---\n",
      "testinstant3300of40430\n",
      "--- 6784.517782211304 seconds ---\n",
      "testinstant3400of40430\n",
      "--- 6989.631498575211 seconds ---\n",
      "testinstant3500of40430\n",
      "--- 7195.920302629471 seconds ---\n",
      "testinstant3600of40430\n",
      "--- 7401.86371922493 seconds ---\n",
      "testinstant3700of40430\n",
      "--- 7607.659499645233 seconds ---\n",
      "testinstant3800of40430\n",
      "--- 7812.693180561066 seconds ---\n",
      "testinstant3900of40430\n",
      "--- 8018.231853246689 seconds ---\n",
      "testinstant4000of40430\n",
      "--- 8223.70148730278 seconds ---\n",
      "testinstant4100of40430\n",
      "--- 8429.242205381393 seconds ---\n",
      "testinstant4200of40430\n",
      "--- 8635.356105804443 seconds ---\n",
      "testinstant4300of40430\n",
      "--- 8841.757357358932 seconds ---\n",
      "testinstant4400of40430\n",
      "--- 9047.237789869308 seconds ---\n",
      "testinstant4500of40430\n",
      "--- 9254.336698293686 seconds ---\n",
      "testinstant4600of40430\n",
      "--- 9459.349341630936 seconds ---\n",
      "testinstant4700of40430\n",
      "--- 9665.307125329971 seconds ---\n",
      "testinstant4800of40430\n",
      "--- 9871.724853754044 seconds ---\n",
      "testinstant4900of40430\n",
      "--- 10076.978122711182 seconds ---\n",
      "testinstant5000of40430\n",
      "--- 10282.77075624466 seconds ---\n",
      "testinstant5100of40430\n",
      "--- 10488.757887601852 seconds ---\n",
      "testinstant5200of40430\n",
      "--- 10693.954661369324 seconds ---\n",
      "testinstant5300of40430\n",
      "--- 10899.849624156952 seconds ---\n",
      "testinstant5400of40430\n",
      "--- 11105.555727005005 seconds ---\n",
      "testinstant5500of40430\n",
      "--- 11311.20347571373 seconds ---\n",
      "testinstant5600of40430\n",
      "--- 11518.404065608978 seconds ---\n",
      "testinstant5700of40430\n",
      "--- 11724.909441709518 seconds ---\n",
      "testinstant5800of40430\n",
      "--- 11930.334391593933 seconds ---\n",
      "testinstant5900of40430\n",
      "--- 12137.240449428558 seconds ---\n",
      "testinstant6000of40430\n",
      "--- 12343.023178100586 seconds ---\n",
      "testinstant6100of40430\n",
      "--- 12548.9246468544 seconds ---\n",
      "testinstant6200of40430\n",
      "--- 12755.636945962906 seconds ---\n",
      "testinstant6300of40430\n",
      "--- 12960.043369531631 seconds ---\n",
      "testinstant6400of40430\n",
      "--- 13164.712100744247 seconds ---\n",
      "testinstant6500of40430\n",
      "--- 13370.115992546082 seconds ---\n",
      "testinstant6600of40430\n",
      "--- 13577.350658893585 seconds ---\n",
      "testinstant6700of40430\n",
      "--- 13783.57282423973 seconds ---\n",
      "testinstant6800of40430\n",
      "--- 13989.465903997421 seconds ---\n",
      "testinstant6900of40430\n",
      "--- 14194.766077280045 seconds ---\n",
      "testinstant7000of40430\n",
      "--- 14399.996344804764 seconds ---\n",
      "testinstant7100of40430\n",
      "--- 14604.136877298355 seconds ---\n",
      "testinstant7200of40430\n",
      "--- 14809.587631702423 seconds ---\n",
      "testinstant7300of40430\n",
      "--- 15016.022173404694 seconds ---\n",
      "testinstant7400of40430\n",
      "--- 15220.254276514053 seconds ---\n",
      "testinstant7500of40430\n",
      "--- 15424.867428541183 seconds ---\n",
      "testinstant7600of40430\n",
      "--- 15631.23587679863 seconds ---\n",
      "testinstant7700of40430\n",
      "--- 15836.87913107872 seconds ---\n",
      "testinstant7800of40430\n",
      "--- 16042.55293750763 seconds ---\n",
      "testinstant7900of40430\n",
      "--- 16249.750075101852 seconds ---\n",
      "testinstant8000of40430\n",
      "--- 16454.870516061783 seconds ---\n",
      "testinstant8100of40430\n",
      "--- 16659.448499917984 seconds ---\n",
      "testinstant8200of40430\n",
      "--- 16865.730754375458 seconds ---\n",
      "testinstant8300of40430\n",
      "--- 17071.521909475327 seconds ---\n",
      "testinstant8400of40430\n",
      "--- 17278.397022008896 seconds ---\n",
      "testinstant8500of40430\n",
      "--- 17483.85110449791 seconds ---\n",
      "testinstant8600of40430\n",
      "--- 17690.28696656227 seconds ---\n",
      "testinstant8700of40430\n",
      "--- 17897.964042663574 seconds ---\n",
      "testinstant8800of40430\n",
      "--- 18104.166754484177 seconds ---\n",
      "testinstant8900of40430\n",
      "--- 18308.673825740814 seconds ---\n",
      "testinstant9000of40430\n",
      "--- 18514.444942712784 seconds ---\n",
      "testinstant9100of40430\n",
      "--- 18718.995523929596 seconds ---\n",
      "testinstant9200of40430\n",
      "--- 18924.470611333847 seconds ---\n",
      "testinstant9300of40430\n",
      "--- 19132.16005396843 seconds ---\n",
      "testinstant9400of40430\n",
      "--- 19338.80464911461 seconds ---\n",
      "testinstant9500of40430\n",
      "--- 19546.118263721466 seconds ---\n",
      "testinstant9600of40430\n",
      "--- 19754.540097236633 seconds ---\n",
      "testinstant9700of40430\n",
      "--- 19960.064583301544 seconds ---\n",
      "testinstant9800of40430\n",
      "--- 20166.041156053543 seconds ---\n",
      "testinstant9900of40430\n",
      "--- 20371.849300146103 seconds ---\n",
      "testinstant10000of40430\n",
      "--- 20578.11133790016 seconds ---\n",
      "testinstant10100of40430\n",
      "--- 20783.806450128555 seconds ---\n",
      "testinstant10200of40430\n",
      "--- 20988.6790163517 seconds ---\n",
      "testinstant10300of40430\n",
      "--- 21194.19729399681 seconds ---\n",
      "testinstant10400of40430\n",
      "--- 21400.90076994896 seconds ---\n",
      "testinstant10500of40430\n",
      "--- 21605.807688236237 seconds ---\n",
      "testinstant10600of40430\n",
      "--- 21811.50022625923 seconds ---\n",
      "testinstant10700of40430\n",
      "--- 22018.33567428589 seconds ---\n",
      "testinstant10800of40430\n",
      "--- 22223.175631046295 seconds ---\n",
      "testinstant10900of40430\n",
      "--- 22429.603367328644 seconds ---\n",
      "testinstant11000of40430\n",
      "--- 22634.50757408142 seconds ---\n",
      "testinstant11100of40430\n",
      "--- 22840.362198591232 seconds ---\n",
      "testinstant11200of40430\n",
      "--- 23045.55313706398 seconds ---\n",
      "testinstant11300of40430\n",
      "--- 23251.20653963089 seconds ---\n",
      "testinstant11400of40430\n",
      "--- 23458.159895420074 seconds ---\n",
      "testinstant11500of40430\n",
      "--- 23664.48028063774 seconds ---\n",
      "testinstant11600of40430\n",
      "--- 23870.01532793045 seconds ---\n",
      "testinstant11700of40430\n",
      "--- 24075.65514445305 seconds ---\n",
      "testinstant11800of40430\n",
      "--- 24281.515754699707 seconds ---\n",
      "testinstant11900of40430\n",
      "--- 24487.818599939346 seconds ---\n",
      "testinstant12000of40430\n",
      "--- 24693.056077241898 seconds ---\n",
      "testinstant12100of40430\n",
      "--- 24899.090066432953 seconds ---\n",
      "testinstant12200of40430\n",
      "--- 25104.888508081436 seconds ---\n",
      "testinstant12300of40430\n",
      "--- 25311.841819763184 seconds ---\n",
      "testinstant12400of40430\n",
      "--- 25518.23162484169 seconds ---\n",
      "testinstant12500of40430\n",
      "--- 25724.225573539734 seconds ---\n",
      "testinstant12600of40430\n",
      "--- 25931.126831054688 seconds ---\n",
      "testinstant12700of40430\n",
      "--- 26135.667515277863 seconds ---\n",
      "testinstant12800of40430\n",
      "--- 26341.29192352295 seconds ---\n",
      "testinstant12900of40430\n",
      "--- 26546.805651903152 seconds ---\n",
      "testinstant13000of40430\n",
      "--- 26752.911787986755 seconds ---\n",
      "testinstant13100of40430\n",
      "--- 26957.16478204727 seconds ---\n",
      "testinstant13200of40430\n",
      "--- 27162.517652988434 seconds ---\n",
      "testinstant13300of40430\n",
      "--- 27368.284197330475 seconds ---\n",
      "testinstant13400of40430\n",
      "--- 27573.422965765 seconds ---\n",
      "testinstant13500of40430\n",
      "--- 27779.26539826393 seconds ---\n",
      "testinstant13600of40430\n",
      "--- 27984.985137462616 seconds ---\n",
      "testinstant13700of40430\n",
      "--- 28191.809875011444 seconds ---\n",
      "testinstant13800of40430\n",
      "--- 28398.492842674255 seconds ---\n",
      "testinstant13900of40430\n",
      "--- 28603.699696540833 seconds ---\n",
      "testinstant14000of40430\n",
      "--- 28809.793870687485 seconds ---\n",
      "testinstant14100of40430\n",
      "--- 29014.739198684692 seconds ---\n",
      "testinstant14200of40430\n",
      "--- 29220.5072350502 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testinstant14300of40430\n",
      "--- 29426.75461292267 seconds ---\n",
      "testinstant14400of40430\n",
      "--- 29633.027809143066 seconds ---\n",
      "testinstant14500of40430\n",
      "--- 29838.08459329605 seconds ---\n",
      "testinstant14600of40430\n",
      "--- 30044.286282539368 seconds ---\n",
      "testinstant14700of40430\n",
      "--- 30249.712182998657 seconds ---\n",
      "testinstant14800of40430\n",
      "--- 30455.949677467346 seconds ---\n",
      "testinstant14900of40430\n",
      "--- 30661.088501930237 seconds ---\n",
      "testinstant15000of40430\n",
      "--- 30866.367333173752 seconds ---\n",
      "testinstant15100of40430\n",
      "--- 31072.05053639412 seconds ---\n",
      "testinstant15200of40430\n",
      "--- 31277.487644672394 seconds ---\n",
      "testinstant15300of40430\n",
      "--- 31481.65869998932 seconds ---\n",
      "testinstant15400of40430\n",
      "--- 31687.949153900146 seconds ---\n",
      "testinstant15500of40430\n",
      "--- 31893.991490125656 seconds ---\n",
      "testinstant15700of40430\n",
      "--- 32305.127695083618 seconds ---\n",
      "testinstant15800of40430\n",
      "--- 32509.79324579239 seconds ---\n",
      "testinstant15900of40430\n",
      "--- 32715.832951784134 seconds ---\n",
      "testinstant16000of40430\n",
      "--- 32920.99843335152 seconds ---\n",
      "testinstant16100of40430\n",
      "--- 33127.1713385582 seconds ---\n",
      "testinstant16200of40430\n",
      "--- 33332.57378387451 seconds ---\n",
      "testinstant16300of40430\n",
      "--- 33537.781356573105 seconds ---\n",
      "testinstant16400of40430\n",
      "--- 33743.789914608 seconds ---\n",
      "testinstant16500of40430\n",
      "--- 33949.506816625595 seconds ---\n",
      "testinstant16600of40430\n",
      "--- 34156.19511795044 seconds ---\n",
      "testinstant16700of40430\n",
      "--- 34361.58364486694 seconds ---\n",
      "testinstant16800of40430\n",
      "--- 34566.76495885849 seconds ---\n",
      "testinstant16900of40430\n",
      "--- 34772.42864370346 seconds ---\n",
      "testinstant17000of40430\n",
      "--- 34978.06287717819 seconds ---\n",
      "testinstant17100of40430\n",
      "--- 35185.55149459839 seconds ---\n",
      "testinstant17200of40430\n",
      "--- 35390.79651594162 seconds ---\n",
      "testinstant17300of40430\n",
      "--- 35596.73445606232 seconds ---\n",
      "testinstant17400of40430\n",
      "--- 35802.28945183754 seconds ---\n",
      "testinstant17500of40430\n",
      "--- 36007.71923351288 seconds ---\n",
      "testinstant17600of40430\n",
      "--- 36214.28760409355 seconds ---\n",
      "testinstant17700of40430\n",
      "--- 36421.1344974041 seconds ---\n",
      "testinstant17800of40430\n",
      "--- 36626.33458471298 seconds ---\n",
      "testinstant17900of40430\n",
      "--- 36831.83482336998 seconds ---\n",
      "testinstant18000of40430\n",
      "--- 37038.41750073433 seconds ---\n",
      "testinstant18100of40430\n",
      "--- 37244.06621980667 seconds ---\n",
      "testinstant18200of40430\n",
      "--- 37449.67792201042 seconds ---\n",
      "testinstant18300of40430\n",
      "--- 37656.16126203537 seconds ---\n",
      "testinstant18400of40430\n",
      "--- 37861.52206301689 seconds ---\n",
      "testinstant18500of40430\n",
      "--- 38066.49676513672 seconds ---\n",
      "testinstant18600of40430\n",
      "--- 38272.221469163895 seconds ---\n",
      "testinstant18700of40430\n",
      "--- 38477.51187086105 seconds ---\n",
      "testinstant18800of40430\n",
      "--- 38683.98736715317 seconds ---\n",
      "testinstant18900of40430\n",
      "--- 38889.69805622101 seconds ---\n",
      "testinstant19000of40430\n",
      "--- 39094.66914844513 seconds ---\n",
      "testinstant19100of40430\n",
      "--- 39301.524884700775 seconds ---\n",
      "testinstant19200of40430\n",
      "--- 39507.422649145126 seconds ---\n",
      "testinstant19300of40430\n",
      "--- 39712.72246456146 seconds ---\n",
      "testinstant19400of40430\n",
      "--- 39917.9937851429 seconds ---\n",
      "testinstant19500of40430\n",
      "--- 40124.62254905701 seconds ---\n",
      "testinstant19600of40430\n",
      "--- 40331.90625047684 seconds ---\n",
      "testinstant19700of40430\n",
      "--- 40537.1025454998 seconds ---\n",
      "testinstant19800of40430\n",
      "--- 40742.591360569 seconds ---\n",
      "testinstant19900of40430\n",
      "--- 40947.30860209465 seconds ---\n",
      "testinstant20000of40430\n",
      "--- 41152.53098607063 seconds ---\n",
      "testinstant20100of40430\n",
      "--- 41359.00537824631 seconds ---\n",
      "testinstant20200of40430\n",
      "--- 41563.65175843239 seconds ---\n",
      "testinstant20300of40430\n",
      "--- 41768.8429415226 seconds ---\n",
      "testinstant20400of40430\n",
      "--- 41975.31606841087 seconds ---\n",
      "testinstant20500of40430\n",
      "--- 42182.1674079895 seconds ---\n",
      "testinstant20600of40430\n",
      "--- 42388.13455557823 seconds ---\n",
      "testinstant20700of40430\n",
      "--- 42593.75816869736 seconds ---\n",
      "testinstant20800of40430\n",
      "--- 42798.80127906799 seconds ---\n",
      "testinstant20900of40430\n",
      "--- 43006.36038899422 seconds ---\n",
      "testinstant21000of40430\n",
      "--- 43212.41992402077 seconds ---\n",
      "testinstant21100of40430\n",
      "--- 43418.478352069855 seconds ---\n",
      "testinstant21200of40430\n",
      "--- 43623.06103491783 seconds ---\n",
      "testinstant21300of40430\n",
      "--- 43828.873775720596 seconds ---\n",
      "testinstant21400of40430\n",
      "--- 44034.68455719948 seconds ---\n",
      "testinstant21500of40430\n",
      "--- 44241.324412584305 seconds ---\n",
      "testinstant21600of40430\n",
      "--- 44446.15189194679 seconds ---\n",
      "testinstant21700of40430\n",
      "--- 44652.056391239166 seconds ---\n",
      "testinstant21800of40430\n",
      "--- 44856.757855176926 seconds ---\n",
      "testinstant21900of40430\n",
      "--- 45064.068542957306 seconds ---\n",
      "testinstant22000of40430\n",
      "--- 45269.82909035683 seconds ---\n",
      "testinstant22100of40430\n",
      "--- 45476.515397548676 seconds ---\n",
      "testinstant22200of40430\n",
      "--- 45680.6268389225 seconds ---\n",
      "testinstant22300of40430\n",
      "--- 45887.602348804474 seconds ---\n",
      "testinstant22400of40430\n",
      "--- 46093.00810956955 seconds ---\n",
      "testinstant22500of40430\n",
      "--- 46298.94937348366 seconds ---\n",
      "testinstant22600of40430\n",
      "--- 46504.285552978516 seconds ---\n",
      "testinstant22700of40430\n",
      "--- 46710.96329116821 seconds ---\n",
      "testinstant22800of40430\n",
      "--- 46916.19958305359 seconds ---\n",
      "testinstant22900of40430\n",
      "--- 47122.31317067146 seconds ---\n",
      "testinstant23000of40430\n",
      "--- 47328.96800351143 seconds ---\n",
      "testinstant23100of40430\n",
      "--- 47535.277873039246 seconds ---\n",
      "testinstant23200of40430\n",
      "--- 47740.68410515785 seconds ---\n",
      "testinstant23300of40430\n",
      "--- 47945.685688495636 seconds ---\n",
      "testinstant23400of40430\n",
      "--- 48151.93655991554 seconds ---\n",
      "testinstant23500of40430\n",
      "--- 48356.56888151169 seconds ---\n",
      "testinstant23600of40430\n",
      "--- 48563.9522922039 seconds ---\n",
      "testinstant23700of40430\n",
      "--- 48769.609808683395 seconds ---\n",
      "testinstant23800of40430\n",
      "--- 48975.43230819702 seconds ---\n",
      "testinstant23900of40430\n",
      "--- 49180.858687877655 seconds ---\n",
      "testinstant24000of40430\n",
      "--- 49386.441494464874 seconds ---\n",
      "testinstant24100of40430\n",
      "--- 49591.93983101845 seconds ---\n",
      "testinstant24200of40430\n",
      "--- 49798.03064584732 seconds ---\n",
      "testinstant24300of40430\n",
      "--- 50004.88060641289 seconds ---\n",
      "testinstant24400of40430\n",
      "--- 50210.37997126579 seconds ---\n",
      "testinstant24500of40430\n",
      "--- 50415.65360021591 seconds ---\n",
      "testinstant24600of40430\n",
      "--- 50622.14106297493 seconds ---\n",
      "testinstant24700of40430\n",
      "--- 50828.55778956413 seconds ---\n",
      "testinstant24800of40430\n",
      "--- 51033.8365957737 seconds ---\n",
      "testinstant24900of40430\n",
      "--- 51239.3624894619 seconds ---\n",
      "testinstant25000of40430\n",
      "--- 51444.939918756485 seconds ---\n",
      "testinstant25100of40430\n",
      "--- 51650.202248096466 seconds ---\n",
      "testinstant25200of40430\n",
      "--- 51857.356847286224 seconds ---\n",
      "testinstant25300of40430\n",
      "--- 52063.79192709923 seconds ---\n",
      "testinstant25400of40430\n",
      "--- 52270.50448203087 seconds ---\n",
      "testinstant25500of40430\n",
      "--- 52477.74006772041 seconds ---\n",
      "testinstant25600of40430\n",
      "--- 52683.230246305466 seconds ---\n",
      "testinstant25700of40430\n",
      "--- 52889.757428884506 seconds ---\n",
      "testinstant25800of40430\n",
      "--- 53096.39808297157 seconds ---\n",
      "testinstant25900of40430\n",
      "--- 53301.86230969429 seconds ---\n",
      "testinstant26000of40430\n",
      "--- 53508.9888446331 seconds ---\n",
      "testinstant26100of40430\n",
      "--- 53714.18318128586 seconds ---\n",
      "testinstant26200of40430\n",
      "--- 53921.21288251877 seconds ---\n",
      "testinstant26300of40430\n",
      "--- 54127.37322330475 seconds ---\n",
      "testinstant26400of40430\n",
      "--- 54332.69257354736 seconds ---\n",
      "testinstant26500of40430\n",
      "--- 54539.108072042465 seconds ---\n",
      "testinstant26600of40430\n",
      "--- 54746.14474606514 seconds ---\n",
      "testinstant26700of40430\n",
      "--- 54951.830582380295 seconds ---\n",
      "testinstant26800of40430\n",
      "--- 55156.86665511131 seconds ---\n",
      "testinstant26900of40430\n",
      "--- 55363.5211148262 seconds ---\n",
      "testinstant27000of40430\n",
      "--- 55569.10344028473 seconds ---\n",
      "testinstant27100of40430\n",
      "--- 55775.64421367645 seconds ---\n",
      "testinstant27200of40430\n",
      "--- 55980.55428695679 seconds ---\n",
      "testinstant27300of40430\n",
      "--- 56186.120156764984 seconds ---\n",
      "testinstant27400of40430\n",
      "--- 56390.41080784798 seconds ---\n",
      "testinstant27500of40430\n",
      "--- 56595.24122285843 seconds ---\n",
      "testinstant27600of40430\n",
      "--- 56800.76094722748 seconds ---\n",
      "testinstant27700of40430\n",
      "--- 57007.75332522392 seconds ---\n",
      "testinstant27800of40430\n",
      "--- 57213.233107328415 seconds ---\n",
      "testinstant27900of40430\n",
      "--- 57418.21733498573 seconds ---\n",
      "testinstant28000of40430\n",
      "--- 57622.87175011635 seconds ---\n",
      "testinstant28100of40430\n",
      "--- 57828.214225530624 seconds ---\n",
      "testinstant28200of40430\n",
      "--- 58034.884551763535 seconds ---\n",
      "testinstant28300of40430\n",
      "--- 58240.56256151199 seconds ---\n",
      "testinstant28400of40430\n",
      "--- 58444.91054105759 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testinstant28500of40430\n",
      "--- 58652.259394168854 seconds ---\n",
      "testinstant28600of40430\n",
      "--- 58858.57175064087 seconds ---\n",
      "testinstant28700of40430\n",
      "--- 59064.39810347557 seconds ---\n",
      "testinstant28800of40430\n",
      "--- 59270.615223646164 seconds ---\n",
      "testinstant28900of40430\n",
      "--- 59476.051790475845 seconds ---\n",
      "testinstant29000of40430\n",
      "--- 59682.82425236702 seconds ---\n",
      "testinstant29100of40430\n",
      "--- 59888.55813455582 seconds ---\n",
      "testinstant29200of40430\n",
      "--- 60094.93422627449 seconds ---\n",
      "testinstant29300of40430\n",
      "--- 60302.69815039635 seconds ---\n",
      "testinstant29400of40430\n",
      "--- 60507.934693574905 seconds ---\n",
      "testinstant29500of40430\n",
      "--- 60712.82272076607 seconds ---\n",
      "testinstant29600of40430\n",
      "--- 60918.77508831024 seconds ---\n",
      "testinstant29700of40430\n",
      "--- 61123.3048248291 seconds ---\n",
      "testinstant29800of40430\n",
      "--- 61328.92486000061 seconds ---\n",
      "testinstant29900of40430\n",
      "--- 61535.02563929558 seconds ---\n",
      "testinstant30000of40430\n",
      "--- 61740.94729757309 seconds ---\n",
      "testinstant30100of40430\n",
      "--- 61947.63135123253 seconds ---\n",
      "testinstant30200of40430\n",
      "--- 62153.548028707504 seconds ---\n",
      "testinstant30300of40430\n",
      "--- 62358.837731838226 seconds ---\n",
      "testinstant30400of40430\n",
      "--- 62563.872990608215 seconds ---\n",
      "testinstant30500of40430\n",
      "--- 62769.82458162308 seconds ---\n",
      "testinstant30600of40430\n",
      "--- 62975.51640152931 seconds ---\n",
      "testinstant30700of40430\n",
      "--- 63182.25687432289 seconds ---\n",
      "testinstant30800of40430\n",
      "--- 63387.80011200905 seconds ---\n",
      "testinstant30900of40430\n",
      "--- 63594.345672130585 seconds ---\n",
      "testinstant31000of40430\n",
      "--- 63800.00428938866 seconds ---\n",
      "testinstant31100of40430\n",
      "--- 64005.734738349915 seconds ---\n",
      "testinstant31200of40430\n",
      "--- 64212.173162937164 seconds ---\n",
      "testinstant31300of40430\n",
      "--- 64417.095009326935 seconds ---\n",
      "testinstant31400of40430\n",
      "--- 64623.796002388 seconds ---\n",
      "testinstant31500of40430\n",
      "--- 64830.83958339691 seconds ---\n",
      "testinstant31600of40430\n",
      "--- 65037.10110163689 seconds ---\n",
      "testinstant31700of40430\n",
      "--- 65244.51047182083 seconds ---\n",
      "testinstant31800of40430\n",
      "--- 65450.576962947845 seconds ---\n",
      "testinstant31900of40430\n",
      "--- 65656.12764668465 seconds ---\n",
      "testinstant32000of40430\n",
      "--- 65861.08905720711 seconds ---\n",
      "testinstant32100of40430\n",
      "--- 66066.71743965149 seconds ---\n",
      "testinstant32200of40430\n",
      "--- 66271.66127324104 seconds ---\n",
      "testinstant32300of40430\n",
      "--- 66477.92325258255 seconds ---\n",
      "testinstant32400of40430\n",
      "--- 66684.94194984436 seconds ---\n",
      "testinstant32500of40430\n",
      "--- 66891.18423485756 seconds ---\n",
      "testinstant32600of40430\n",
      "--- 67097.30806398392 seconds ---\n",
      "testinstant32700of40430\n",
      "--- 67304.24548172951 seconds ---\n",
      "testinstant32800of40430\n",
      "--- 67511.0744638443 seconds ---\n",
      "testinstant32900of40430\n",
      "--- 67716.49725937843 seconds ---\n",
      "testinstant33000of40430\n",
      "--- 67922.47061729431 seconds ---\n",
      "testinstant33100of40430\n",
      "--- 68126.87979054451 seconds ---\n",
      "testinstant33200of40430\n",
      "--- 68332.6112203598 seconds ---\n",
      "testinstant33300of40430\n",
      "--- 68538.22145032883 seconds ---\n",
      "testinstant33400of40430\n",
      "--- 68744.4698574543 seconds ---\n",
      "testinstant33500of40430\n",
      "--- 68951.66078925133 seconds ---\n",
      "testinstant33600of40430\n",
      "--- 69158.79741334915 seconds ---\n",
      "testinstant33700of40430\n",
      "--- 69363.71982622147 seconds ---\n",
      "testinstant33800of40430\n",
      "--- 69569.17612576485 seconds ---\n",
      "testinstant33900of40430\n",
      "--- 69776.2767829895 seconds ---\n",
      "testinstant34000of40430\n",
      "--- 69981.239184618 seconds ---\n",
      "testinstant34100of40430\n",
      "--- 70186.32945942879 seconds ---\n",
      "testinstant34200of40430\n",
      "--- 70391.56061887741 seconds ---\n",
      "testinstant34300of40430\n",
      "--- 70596.31273055077 seconds ---\n",
      "testinstant34400of40430\n",
      "--- 70802.28789806366 seconds ---\n",
      "testinstant34500of40430\n",
      "--- 71008.02144551277 seconds ---\n",
      "testinstant34600of40430\n",
      "--- 71214.64732670784 seconds ---\n",
      "testinstant34700of40430\n",
      "--- 71420.44562339783 seconds ---\n",
      "testinstant34800of40430\n",
      "--- 71625.67406749725 seconds ---\n",
      "testinstant34900of40430\n",
      "--- 71831.22179913521 seconds ---\n",
      "testinstant35000of40430\n",
      "--- 72038.17420244217 seconds ---\n",
      "testinstant35100of40430\n",
      "--- 72243.48685479164 seconds ---\n",
      "testinstant35200of40430\n",
      "--- 72450.20558571815 seconds ---\n",
      "testinstant35300of40430\n",
      "--- 72655.57329177856 seconds ---\n",
      "testinstant35400of40430\n",
      "--- 72859.93807268143 seconds ---\n",
      "testinstant35500of40430\n",
      "--- 73065.75092697144 seconds ---\n",
      "testinstant35600of40430\n",
      "--- 73271.1361527443 seconds ---\n",
      "testinstant35700of40430\n",
      "--- 73477.05512928963 seconds ---\n",
      "testinstant35800of40430\n",
      "--- 73683.06969475746 seconds ---\n",
      "testinstant35900of40430\n",
      "--- 73888.39902806282 seconds ---\n",
      "testinstant36000of40430\n",
      "--- 74093.83002257347 seconds ---\n",
      "testinstant36100of40430\n",
      "--- 74298.53220272064 seconds ---\n",
      "testinstant36200of40430\n",
      "--- 74503.8665368557 seconds ---\n",
      "testinstant36300of40430\n",
      "--- 74709.27503347397 seconds ---\n",
      "testinstant36400of40430\n",
      "--- 74915.82576346397 seconds ---\n",
      "testinstant36500of40430\n",
      "--- 75122.6983590126 seconds ---\n",
      "testinstant36600of40430\n",
      "--- 75328.15257740021 seconds ---\n",
      "testinstant36700of40430\n",
      "--- 75535.16062068939 seconds ---\n",
      "testinstant36800of40430\n",
      "--- 75741.33641815186 seconds ---\n",
      "testinstant36900of40430\n",
      "--- 75948.83724689484 seconds ---\n",
      "testinstant37000of40430\n",
      "--- 76155.2882502079 seconds ---\n",
      "testinstant37100of40430\n",
      "--- 76361.43380713463 seconds ---\n",
      "testinstant37200of40430\n",
      "--- 76569.16959810257 seconds ---\n",
      "testinstant37300of40430\n",
      "--- 76775.34822559357 seconds ---\n",
      "testinstant37400of40430\n",
      "--- 76980.73217725754 seconds ---\n",
      "testinstant37500of40430\n",
      "--- 77186.22234129906 seconds ---\n",
      "testinstant37600of40430\n",
      "--- 77391.5161588192 seconds ---\n",
      "testinstant37700of40430\n",
      "--- 77597.14402961731 seconds ---\n",
      "testinstant37800of40430\n",
      "--- 77802.34445333481 seconds ---\n",
      "testinstant37900of40430\n",
      "--- 78007.63848185539 seconds ---\n",
      "testinstant38000of40430\n",
      "--- 78215.32960987091 seconds ---\n",
      "testinstant38100of40430\n",
      "--- 78421.14572620392 seconds ---\n",
      "testinstant38200of40430\n",
      "--- 78628.67405676842 seconds ---\n",
      "testinstant38300of40430\n",
      "--- 78834.83911156654 seconds ---\n",
      "testinstant38400of40430\n",
      "--- 79040.12087798119 seconds ---\n",
      "testinstant38500of40430\n",
      "--- 79245.16440320015 seconds ---\n",
      "testinstant38600of40430\n",
      "--- 79450.73336791992 seconds ---\n",
      "testinstant38700of40430\n",
      "--- 79655.75289273262 seconds ---\n",
      "testinstant38800of40430\n",
      "--- 79861.47804164886 seconds ---\n",
      "testinstant38900of40430\n",
      "--- 80068.01917481422 seconds ---\n",
      "testinstant39000of40430\n",
      "--- 80272.85417032242 seconds ---\n",
      "testinstant39100of40430\n",
      "--- 80478.37818551064 seconds ---\n",
      "testinstant39200of40430\n",
      "--- 80683.43006658554 seconds ---\n",
      "testinstant39300of40430\n",
      "--- 80888.34085392952 seconds ---\n",
      "testinstant39400of40430\n",
      "--- 81094.46389365196 seconds ---\n",
      "testinstant39500of40430\n",
      "--- 81301.79601216316 seconds ---\n",
      "testinstant39600of40430\n",
      "--- 81507.27896547318 seconds ---\n",
      "testinstant39700of40430\n",
      "--- 81714.235060215 seconds ---\n",
      "testinstant39800of40430\n",
      "--- 81918.98823618889 seconds ---\n",
      "testinstant39900of40430\n",
      "--- 82124.13500928879 seconds ---\n",
      "testinstant40000of40430\n",
      "--- 82331.38363313675 seconds ---\n",
      "testinstant40100of40430\n",
      "--- 82536.57245063782 seconds ---\n",
      "testinstant40200of40430\n",
      "--- 82742.08789944649 seconds ---\n",
      "testinstant40300of40430\n",
      "--- 82947.0963382721 seconds ---\n",
      "testinstant40400of40430\n",
      "--- 83152.80381011963 seconds ---\n"
     ]
    }
   ],
   "source": [
    "(aopc_TransCAM, aopc_Rawatt, aopc_PartialLRP, aopc_Rollout, aopc_LRP,\n",
    " aopc_TransCAM_del, aopc_Rawatt_del, aopc_PartialLRP_del, aopc_Rollout_del, aopc_LRP_del,\n",
    " k_TransCAM, k_Rawatt, k_PartialLRP, k_Rollout, k_LRP,\n",
    " logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP,\n",
    " logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del) = test(model, explanations, to_test, degrade_step = 10, seg_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc6803f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14013042 0.14385433 0.14406817 0.14090796 0.1439708\n",
      "0.011760421 0.011759466 0.011756457 0.011767804 0.011716735\n",
      "0.3373943705526535 1.0 0.9489880141499848 1.0 0.23018006844603045\n",
      "0.07722506275320187 0.16699648274011783 0.16729933146995324 0.22675414133424399 0.10173543299925784\n",
      "-0.34358963973052786 -0.21935259867999082 -0.21926288507983355 -0.27490625630511006 -0.2539098157754917\n"
     ]
    }
   ],
   "source": [
    "print(aopc_TransCAM,aopc_Rawatt,aopc_PartialLRP,aopc_Rollout,aopc_LRP)\n",
    "print(aopc_TransCAM_del,aopc_Rawatt_del,aopc_PartialLRP_del,aopc_Rollout_del,aopc_LRP_del)\n",
    "print(k_TransCAM,k_Rawatt,k_PartialLRP,k_Rollout,k_LRP)\n",
    "print(logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP)\n",
    "print(logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "80b0558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time: 83152.80381011963 for 40430 instances\n",
    "minutes = 83152/60\n",
    "hours = 23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51df1ca9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'summary' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m(model)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'summary' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab33039e",
   "metadata": {},
   "source": [
    "# Single Example Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5aa56044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expln_norm(expln):\n",
    "    expln = (expln - expln.min()) / (expln.max()- expln.min())\n",
    "    return expln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13079be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_text_attr(expln,str_list,is_relu = True):\n",
    "    if is_relu:\n",
    "        rgb = lambda x: '0,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: max(x, 0) * 10\n",
    "    else:\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: x * -5 if x < 0 else x * 5\n",
    "    attrs = list(expln)\n",
    "    subwords = str_list\n",
    "    \n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(subwords, attrs)\n",
    "    ]\n",
    "    \n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c02e88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, text_words, label = preprocess_sample(tokenized_qqp,index=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8693c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the explanations generator\n",
    "explanations = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c37cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwbw/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "TransCAM_expln, LRP_expln, PartialLRP_expln, Att_expln, Rollout_expln = \\\n",
    "       generate_explns(explanations, input_ids, attention_mask, start_layer=0, true_class = label, is_true = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab1f539a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.19680285453796387)\">how</mark> <mark style=\"background-color:rgba(0,255,0,0.2843285799026489)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.5239362120628357)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,0.862335205078125)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,2.197042465209961)\">made</mark> <mark style=\"background-color:rgba(0,255,0,2.465100049972534)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,1.0175567865371704)\">how</mark> <mark style=\"background-color:rgba(0,255,0,0.29597413539886475)\">do</mark> <mark style=\"background-color:rgba(0,255,0,0.43843138217926025)\">you</mark> <mark style=\"background-color:rgba(0,255,0,0.48550838232040405)\">make</mark> <mark style=\"background-color:rgba(0,255,0,0.4854544401168823)\">sugar</mark> <mark style=\"background-color:rgba(0,255,0,0.77659672498703)\">cookies</mark> <mark style=\"background-color:rgba(0,255,0,1.7031183242797852)\">without</mark> <mark style=\"background-color:rgba(0,255,0,1.0804768800735474)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,2.3344335556030273)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TransCAM_expln = expln_norm(TransCAM_expln)\n",
    "show_text_attr(TransCAM_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "38658983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,1.8823418617248535)\">how</mark> <mark style=\"background-color:rgba(0,255,0,2.116598129272461)\">is</mark> <mark style=\"background-color:rgba(0,255,0,1.4516252279281616)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,1.6400246620178223)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,2.553156614303589)\">made</mark> <mark style=\"background-color:rgba(0,255,0,3.6090362071990967)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,3.5186281204223633)\">how</mark> <mark style=\"background-color:rgba(0,255,0,3.0200462341308594)\">do</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">you</mark> <mark style=\"background-color:rgba(0,255,0,4.3297295570373535)\">make</mark> <mark style=\"background-color:rgba(0,255,0,4.008004665374756)\">sugar</mark> <mark style=\"background-color:rgba(0,255,0,3.540240526199341)\">cookies</mark> <mark style=\"background-color:rgba(0,255,0,3.6717569828033447)\">without</mark> <mark style=\"background-color:rgba(0,255,0,3.337437629699707)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,3.123120069503784)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,3.885434865951538)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LRP_expln = expln_norm(LRP_expln)\n",
    "show_text_attr(LRP_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ad9fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,2.068115711212158)\">how</mark> <mark style=\"background-color:rgba(0,255,0,2.2958712577819824)\">is</mark> <mark style=\"background-color:rgba(0,255,0,1.4951790571212769)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,1.6338508129119873)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,2.6932897567749023)\">made</mark> <mark style=\"background-color:rgba(0,255,0,4.348810195922852)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,3.7892162799835205)\">how</mark> <mark style=\"background-color:rgba(0,255,0,3.259085178375244)\">do</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">you</mark> <mark style=\"background-color:rgba(0,255,0,4.72081184387207)\">make</mark> <mark style=\"background-color:rgba(0,255,0,4.085805892944336)\">sugar</mark> <mark style=\"background-color:rgba(0,255,0,3.7497243881225586)\">cookies</mark> <mark style=\"background-color:rgba(0,255,0,2.936621904373169)\">without</mark> <mark style=\"background-color:rgba(0,255,0,2.6104307174682617)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,2.5521397590637207)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,3.5443708896636963)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PartialLRP_expln = expln_norm(PartialLRP_expln)\n",
    "show_text_attr(PartialLRP_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bb8055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,2.9692342281341553)\">how</mark> <mark style=\"background-color:rgba(0,255,0,2.365522861480713)\">is</mark> <mark style=\"background-color:rgba(0,255,0,4.172190189361572)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,3.7625553607940674)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,3.719587564468384)\">made</mark> <mark style=\"background-color:rgba(0,255,0,4.107601642608643)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,2.8393115997314453)\">how</mark> <mark style=\"background-color:rgba(0,255,0,2.140739679336548)\">do</mark> <mark style=\"background-color:rgba(0,255,0,3.3369672298431396)\">you</mark> <mark style=\"background-color:rgba(0,255,0,3.457179069519043)\">make</mark> <mark style=\"background-color:rgba(0,255,0,3.4876465797424316)\">sugar</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">cookies</mark> <mark style=\"background-color:rgba(0,255,0,4.128668308258057)\">without</mark> <mark style=\"background-color:rgba(0,255,0,4.1073408126831055)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,3.6225404739379883)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,4.004746437072754)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Att_expln = expln_norm(Att_expln)\n",
    "show_text_attr(Att_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9982ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.9350777864456177)\">how</mark> <mark style=\"background-color:rgba(0,255,0,1.1439518928527832)\">is</mark> <mark style=\"background-color:rgba(0,255,0,0.7618656158447266)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,0.7103333473205566)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,1.7558382749557495)\">made</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,1.7735481262207031)\">how</mark> <mark style=\"background-color:rgba(0,255,0,1.5595815181732178)\">do</mark> <mark style=\"background-color:rgba(0,255,0,1.7625099420547485)\">you</mark> <mark style=\"background-color:rgba(0,255,0,2.108316659927368)\">make</mark> <mark style=\"background-color:rgba(0,255,0,1.7002241611480713)\">sugar</mark> <mark style=\"background-color:rgba(0,255,0,2.2494659423828125)\">cookies</mark> <mark style=\"background-color:rgba(0,255,0,1.2512986660003662)\">without</mark> <mark style=\"background-color:rgba(0,255,0,1.0859837532043457)\">vanilla</mark> <mark style=\"background-color:rgba(0,255,0,0.9713597297668457)\">extract</mark> <mark style=\"background-color:rgba(0,255,0,2.478780508041382)\">?</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Rollout_expln = expln_norm(Rollout_expln)\n",
    "show_text_attr(Rollout_expln,text_words,is_relu = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
