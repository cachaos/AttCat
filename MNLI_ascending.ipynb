{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d90a11d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import argparse\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm as tqdm\n",
    "from scipy.special import softmax\n",
    "import scipy.stats as stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "from captum.attr import visualization\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from BERT_explainability.modules.BERT.BertForSequenceClassification import BertForSequenceClassification\n",
    "\n",
    "\n",
    "###mods\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a936fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset, load_metric \n",
    "from datasets import list_datasets, list_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0661e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model   \n",
    "model = BertForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-MNLI\").to(\"cuda\")\n",
    "model.eval()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-MNLI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aad9c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f9ebe784674ad8aa7562b7ee65bcd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = \"glue\"\n",
    "task = \"mnli\" # select a task\n",
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mnli-mm\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}\n",
    "special_tokens = {101,102}    \n",
    "sentence1_key, sentence2_key = task_to_keys[task]\n",
    "\n",
    "mnli = load_dataset(dataset, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09acb1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, padding=False, max_length=tokenizer.model_max_length, truncation=True)\n",
    "    \n",
    "       # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if \"label\" in examples:\n",
    "        result[\"label\"] = examples[\"label\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1950a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-efd8d860162b226b.arrow\n",
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7f04ef593885d7aa.arrow\n",
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-045fb221679771db.arrow\n",
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-a0dde9fda687970e.arrow\n",
      "Loading cached processed dataset at /home/anwbw/.cache/huggingface/datasets/glue/mnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-78337ecc4cc0d642.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_mnli = mnli.map(preprocess_function, batched=True, remove_columns=mnli[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8d5108b",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = {101,102}    \n",
    "mask = \"[PAD]\"\n",
    "mask_id = 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607e60fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sample(tokenized_mnli,index):\n",
    "    input_ids = tokenized_mnli['validation_matched'][index]['input_ids']\n",
    "    text_ids = (torch.tensor([input_ids])).to(\"cuda\")\n",
    "    text_words = tokenizer.convert_ids_to_tokens(text_ids[0])\n",
    "    \n",
    "    att_mask = tokenized_mnli['validation_matched'][index]['attention_mask']\n",
    "    special_idxs = [x for x, y in list(enumerate(input_ids)) if y in special_tokens]\n",
    "    att_mask = [0 if index in special_idxs else 1 for index, item in enumerate(att_mask)]\n",
    "    att_mask = (torch.tensor([att_mask])).to(\"cuda\")\n",
    "    label = tokenized_mnli['validation_matched'][index]['label']\n",
    "    \n",
    "    return text_ids, att_mask, text_words, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aca63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_instance(instance):\n",
    "    input_ids = instance['input_ids']\n",
    "    text_ids = (torch.tensor([input_ids])).to(\"cuda\")\n",
    "    text_words = tokenizer.convert_ids_to_tokens(text_ids[0])\n",
    "    \n",
    "    att_mask = instance['attention_mask']\n",
    "    special_idxs = [x for x, y in list(enumerate(input_ids)) if y in special_tokens]\n",
    "    att_mask = [0 if index in special_idxs else 1 for index, item in enumerate(att_mask)]\n",
    "    att_mask = (torch.tensor([att_mask])).to(\"cuda\")\n",
    "    label = instance['label']\n",
    "    \n",
    "    return text_ids, att_mask, text_words, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8289cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute rollout between attention layers\n",
    "def compute_rollout_attention(all_layer_matrices, start_layer=0):\n",
    "    \n",
    "    # adding residual consideration- code adapted from https://github.com/samiraabnar/attention_flow\n",
    "    num_tokens = all_layer_matrices[0].shape[1]\n",
    "    batch_size = all_layer_matrices[0].shape[0]\n",
    "    eye = torch.eye(num_tokens).expand(batch_size, num_tokens, num_tokens).to(all_layer_matrices[0].device)\n",
    "    all_layer_matrices = [all_layer_matrices[i] + eye for i in range(len(all_layer_matrices))]\n",
    "    matrices_aug = [all_layer_matrices[i] / all_layer_matrices[i].sum(dim=-1, keepdim=True)\n",
    "                          for i in range(len(all_layer_matrices))]\n",
    "    joint_attention = matrices_aug[start_layer]\n",
    "    for i in range(start_layer+1, len(matrices_aug)):\n",
    "        joint_attention = matrices_aug[i].bmm(joint_attention)\n",
    "        \n",
    "    return joint_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66061f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "\n",
    "    \n",
    "    def generate_TransCAM(self, input_ids, attention_mask,\n",
    "                          index=None, start_layer=0):\n",
    "\n",
    "        result = self.model(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        \n",
    "        output = result[0]\n",
    "        hs = result[1]\n",
    "\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "\n",
    "        for blk_id in range(len(blocks)):\n",
    "            hs[blk_id].retain_grad()\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cams = {}\n",
    "        for blk_id in range(len(blocks)):\n",
    "            hs_grads = hs[blk_id].grad\n",
    "            \n",
    "            att = blocks[blk_id].attention.self.get_attn().squeeze(0)\n",
    "            att = att.mean(dim=0)\n",
    "            att = att.mean(dim=0)\n",
    "            \n",
    "            cat = (hs_grads * hs[blk_id]).sum(dim=-1).squeeze(0)\n",
    "            cat = cat * att\n",
    "            cams[blk_id] = cat\n",
    "            \n",
    "        trans_expln = sum(cams.values())\n",
    "\n",
    "        return trans_expln\n",
    "\n",
    "    def generate_LRP(self, input_ids, attention_mask,\n",
    "                     index=None, start_layer=11):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cams = []\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "        for blk in blocks:\n",
    "            grad = blk.attention.self.get_attn_gradients()\n",
    "            cam = blk.attention.self.get_attn_cam()\n",
    "            cam = cam[0].reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "            grad = grad[0].reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "            cam = grad * cam\n",
    "            cam = cam.clamp(min=0).mean(dim=0)\n",
    "            cams.append(cam.unsqueeze(0))\n",
    "        rollout = compute_rollout_attention(cams, start_layer=start_layer)\n",
    "        rollout[:, 0, 0] = 0\n",
    "        return rollout[:, 0]\n",
    "\n",
    "\n",
    "    def generate_LRP_last_layer(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn_cam()[0]\n",
    "        cam = cam.clamp(min=0).mean(dim=0).unsqueeze(0)\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]\n",
    "\n",
    "    def generate_full_lrp(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        cam = self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "        cam = cam.sum(dim=2)\n",
    "        cam[:, 0] = 0\n",
    "        return cam\n",
    "\n",
    "    def generate_attn_last_layer(self, input_ids, attention_mask,\n",
    "                     index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn()[0]\n",
    "        cam = cam.mean(dim=0).unsqueeze(0)\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]\n",
    "\n",
    "    def generate_rollout(self, input_ids, attention_mask, start_layer=0, index=None):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        blocks = self.model.bert.encoder.layer\n",
    "        all_layer_attentions = []\n",
    "        for blk in blocks:\n",
    "            attn_heads = blk.attention.self.get_attn()\n",
    "            avg_heads = (attn_heads.sum(dim=1) / attn_heads.shape[1]).detach()\n",
    "            all_layer_attentions.append(avg_heads)\n",
    "        rollout = compute_rollout_attention(all_layer_attentions, start_layer=start_layer)\n",
    "        rollout[:, 0, 0] = 0\n",
    "        return rollout[:, 0]\n",
    "\n",
    "    def generate_attn_gradcam(self, input_ids, attention_mask, index=None):\n",
    "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        kwargs = {\"alpha\": 1}\n",
    "\n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy(), axis=-1)\n",
    "\n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0, index] = 1\n",
    "        one_hot_vector = one_hot\n",
    "        one_hot = torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        one_hot = torch.sum(one_hot.cuda() * output)\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph=True)\n",
    "\n",
    "        self.model.relprop(torch.tensor(one_hot_vector).to(input_ids.device), **kwargs)\n",
    "\n",
    "        cam = self.model.bert.encoder.layer[-1].attention.self.get_attn()\n",
    "        grad = self.model.bert.encoder.layer[-1].attention.self.get_attn_gradients()\n",
    "\n",
    "        cam = cam[0].reshape(-1, cam.shape[-1], cam.shape[-1])\n",
    "        grad = grad[0].reshape(-1, grad.shape[-1], grad.shape[-1])\n",
    "        grad = grad.mean(dim=[1, 2], keepdim=True)\n",
    "        cam = (cam * grad).mean(0).clamp(min=0).unsqueeze(0)\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
    "        cam[:, 0, 0] = 0\n",
    "        return cam[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584744a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explns(explanations, input_ids, attention_mask, start_layer=0, true_class = 1, is_true = True):\n",
    "    \n",
    "    if is_true:\n",
    "        # TransCAM\n",
    "        TransCAM_expln = explanations.generate_TransCAM(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)\n",
    "        # LRP\n",
    "        LRP_expln = explanations.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)[0]\n",
    "        # PartialLRP\n",
    "        PartialLRP_expln = explanations.generate_LRP_last_layer(input_ids=input_ids, \n",
    "                                                     index=true_class, attention_mask=attention_mask)[0]\n",
    "        # FullLRP\n",
    "        # FullLRP_expln = explanations.generate_full_lrp(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                           index=true_class)[0]\n",
    "        # Att\n",
    "        Att_expln = explanations.generate_attn_last_layer(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class)[0]\n",
    "        # Rollout\n",
    "        Rollout_expln = explanations.generate_rollout(input_ids=input_ids, attention_mask=attention_mask,      \n",
    "                                                    index=true_class, start_layer=0)[0]\n",
    "        # Att_Gradcam\n",
    "        # Att_Gradcam_expln = explanations.generate_attn_gradcam(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]    \n",
    "        \n",
    "    else:\n",
    "        if true_class == 0:\n",
    "            true_class = 1-true_class\n",
    "        else:\n",
    "            true_class = true_class - 1\n",
    "        # TransCAM\n",
    "        TransCAM_expln = explanations.generate_TransCAM(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)\n",
    "        # LRP\n",
    "        LRP_expln = explanations.generate_LRP(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=start_layer)[0]\n",
    "        # PartialLRP\n",
    "        PartialLRP_expln = explanations.generate_LRP_last_layer(input_ids=input_ids, \n",
    "                                                    index=true_class, attention_mask=attention_mask)[0]\n",
    "        # FullLRP\n",
    "        # FullLRP_expln = explanations.generate_full_lrp(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]\n",
    "        # Att\n",
    "        Att_expln = explanations.generate_attn_last_layer(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class)[0]\n",
    "        # Rollout\n",
    "        Rollout_expln = explanations.generate_rollout(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                                                    index=true_class, start_layer=0)[0]\n",
    "        # Att_Gradcam\n",
    "        # Att_Gradcam_expln = explanations.generate_attn_gradcam(input_ids=input_ids, attention_mask=attention_mask, \n",
    "        #                                            index=true_class)[0]\n",
    "    \n",
    "    # return TransCAM_expln, LRP_expln, PartialLRP_expln, FullLRP_expln, Att_expln, Rollout_expln, Att_Gradcam_expln\n",
    "    return TransCAM_expln, Att_expln, PartialLRP_expln, Rollout_expln, LRP_expln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d40fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text_ids, target, att_mask=None, seg_ids=None):\n",
    "    out = model(text_ids, attention_mask=att_mask, token_type_ids=seg_ids)\n",
    "    prob = out[0]\n",
    "    pred_class = torch.argmax(prob, axis=1).cpu().detach().numpy()\n",
    "    pred_class_prob = softmax(prob.cpu().detach().numpy(), axis=1)\n",
    "    return pred_class[0], pred_class_prob[:, target][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279459b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_words(sorted_idx, text_words, text_ids, replaced_num, seg_ids=None):\n",
    "    to_be_replaced_idx = []\n",
    "    i= 0\n",
    "    while len(to_be_replaced_idx) < replaced_num and i!=len(text_words)-1:\n",
    "        current_idx = sorted_idx[i]\n",
    "        if text_words[current_idx] not in special_tokens:\n",
    "            to_be_replaced_idx.append(current_idx)\n",
    "        i += 1\n",
    "    remaining_idx = sorted(list(set(sorted_idx) - set(to_be_replaced_idx)))\n",
    "    truncated_text_ids = text_ids[0, np.array(remaining_idx)]\n",
    "    if seg_ids is not None:\n",
    "        seg_ids = seg_ids[0, np.array(remaining_idx)]\n",
    "    truncated_text_words = np.array(text_words)[remaining_idx]\n",
    "    return truncated_text_ids.unsqueeze(0), truncated_text_words, seg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e3d12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c32ca46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_words(sorted_idx, text_words, text_ids, replaced_num, mask, mask_id):\n",
    "    to_be_replaced_idx = []\n",
    "    i= 0\n",
    "    while len(to_be_replaced_idx) < replaced_num and i!=len(text_words)-1:\n",
    "        current_idx = sorted_idx[i]\n",
    "        if text_words[current_idx] not in special_tokens:\n",
    "            to_be_replaced_idx.append(current_idx)\n",
    "        i += 1\n",
    "    replaced_text_ids = text_ids.clone()\n",
    "    replaced_text_ids[0, to_be_replaced_idx] = mask_id\n",
    "    replaced_text_words = np.copy(text_words)\n",
    "    replaced_text_words[to_be_replaced_idx] = mask\n",
    "    return replaced_text_ids, replaced_text_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2df7fc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_aopc(original_probs, degradation_probs):\n",
    "    original_probs = np.array(original_probs)\n",
    "    degradation_probs = np.array(degradation_probs)\n",
    "    \n",
    "    diffs = []\n",
    "    for i in range(len(original_probs)):\n",
    "        diffs_k = []\n",
    "        for j in range(9):\n",
    "            diff = original_probs[i] - degradation_probs[i][j]\n",
    "            diffs_k.append(np.abs(diff))\n",
    "        diffs.append(diffs_k)\n",
    "\n",
    "    result = np.mean(diffs, axis=0)\n",
    "    aopc = np.mean(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cal_logodds(original_probs, degradation_probs):\n",
    "    original_probs = np.array(original_probs)\n",
    "    degradation_probs = np.array(degradation_probs)\n",
    "    \n",
    "    ratios = []\n",
    "    for i in range(len(original_probs)):\n",
    "        ratios_k = []\n",
    "        for j in range(9):\n",
    "            ratio = math.log(degradation_probs[i][j] / original_probs[i])\n",
    "            ratios_k.append(ratio)\n",
    "        ratios.append(ratios_k)\n",
    "\n",
    "    result = np.mean(ratios, axis=0)\n",
    "    logodds = np.mean(result)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def cal_kendaltau(attribution1, attribution2,):\n",
    "\n",
    "    sorted_idx1 = np.argsort(-attribution1)\n",
    "    sorted_idx2 = np.argsort(-attribution2)\n",
    "\n",
    "    tau, p_value = stats.kendalltau(sorted_idx1, sorted_idx2)\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1612e77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, explanations, test_data, degrade_step = 10, seg_ids=None):\n",
    "    \n",
    "    original_probs = []\n",
    "    original_accs = [] \n",
    "    \n",
    "    degradation_probs_TransCAM = []\n",
    "    degradation_accs_TransCAM = []\n",
    "    del_probs_TransCAM = []\n",
    "    del_accs_TransCAM = []\n",
    "    \n",
    "    degradation_probs_Rawatt = []\n",
    "    degradation_accs_Rawatt = []\n",
    "    del_probs_Rawatt = []\n",
    "    del_accs_Rawatt = []\n",
    "    \n",
    "    degradation_probs_PartialLRP = []\n",
    "    degradation_accs_PartialLRP = []\n",
    "    del_probs_PartialLRP = []\n",
    "    del_accs_PartialLRP = []\n",
    "    \n",
    "    degradation_probs_Rollout = []\n",
    "    degradation_accs_Rollout = []\n",
    "    del_probs_Rollout = []\n",
    "    del_accs_Rollout = []\n",
    "    \n",
    "    degradation_probs_LRP = []\n",
    "    degradation_accs_LRP = []\n",
    "    del_probs_LRP = []\n",
    "    del_accs_LRP = []\n",
    "    \n",
    "    kendaltaus_TransCAM = []\n",
    "    kendaltaus_Rawatt = []\n",
    "    kendaltaus_PartialLRP = []\n",
    "    kendaltaus_Rollout = []\n",
    "    kendaltaus_LRP = []\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "    for i, test_instance in enumerate(test_data):\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            print(\"testinstant\" + str(i) + \"of\" + str(len(test_data)))\n",
    "            print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "\n",
    "        text_ids, att_mask, text_words, target = preprocess_instance(test_instance)\n",
    "        \n",
    "        # get truc words number\n",
    "        total_len = len(text_words)\n",
    "        if total_len< 10: \n",
    "            continue\n",
    "        granularity = np.linspace(0, 1, degrade_step)\n",
    "        trunc_words_num = [int(g) for g in np.round(granularity*total_len)]\n",
    "        trunc_words_num = list(dict.fromkeys(trunc_words_num))\n",
    "        \n",
    "        original_class, original_prob = predict(model, text_ids, target)\n",
    "        \n",
    "        # get attributions\n",
    "        attribution_TransCAM, attribution_Rawatt, attribution_PartialLRP, attribution_Rollout, attribution_LRP = \\\n",
    "        generate_explns(explanations, text_ids, att_mask, start_layer=0, true_class = target, is_true = True) \n",
    "        \n",
    "        attribution_TransCAM_F, attribution_Rawatt_F, attribution_PartialLRP_F, attribution_Rollout_F, attribution_LRP_F = \\\n",
    "        generate_explns(explanations, text_ids, att_mask, start_layer=0, true_class = target, is_true = False) \n",
    "        \n",
    "        # conver to cpu numpy\n",
    "        attribution_TransCAM = attribution_TransCAM.cpu().detach().numpy()\n",
    "        attribution_Rawatt = attribution_Rawatt.cpu().detach().numpy()\n",
    "        attribution_PartialLRP = attribution_PartialLRP.cpu().detach().numpy()\n",
    "        attribution_Rollout = attribution_Rollout.cpu().detach().numpy()\n",
    "        attribution_LRP = attribution_LRP.cpu().detach().numpy()\n",
    "        \n",
    "        # conver to cpu numpy\n",
    "        attribution_TransCAM_F = attribution_TransCAM_F.cpu().detach().numpy()\n",
    "        attribution_Rawatt_F = attribution_Rawatt_F.cpu().detach().numpy()\n",
    "        attribution_PartialLRP_F = attribution_PartialLRP_F.cpu().detach().numpy()\n",
    "        attribution_Rollout_F = attribution_Rollout_F.cpu().detach().numpy()\n",
    "        attribution_LRP_F = attribution_LRP_F.cpu().detach().numpy()\n",
    "        \n",
    "        # get sorted_idx - ascending\n",
    "        sorted_idx_TransCAM = np.argsort(attribution_TransCAM)\n",
    "        sorted_idx_Rawatt = np.argsort(attribution_Rawatt)\n",
    "        sorted_idx_PartialLRP = np.argsort(attribution_PartialLRP)\n",
    "        sorted_idx_Rollout = np.argsort(attribution_Rollout)\n",
    "        sorted_idx_LRP = np.argsort(attribution_LRP)\n",
    "        \n",
    "        instance_degradation_probs_TransCAM = []\n",
    "        instance_degradation_accs_TransCAM = []\n",
    "        instance_replace_probs_TransCAM = []\n",
    "        instance_replace_accs_TransCAM = []\n",
    "        \n",
    "        instance_degradation_probs_Rawatt = []\n",
    "        instance_degradation_accs_Rawatt = []\n",
    "        instance_replace_probs_Rawatt = []\n",
    "        instance_replace_accs_Rawatt = []\n",
    "        \n",
    "        instance_degradation_probs_PartialLRP = []\n",
    "        instance_degradation_accs_PartialLRP = []\n",
    "        instance_replace_probs_PartialLRP = []\n",
    "        instance_replace_accs_PartialLRP = []\n",
    "        \n",
    "        instance_degradation_probs_Rollout = []\n",
    "        instance_degradation_accs_Rollout = []\n",
    "        instance_replace_probs_Rollout = []\n",
    "        instance_replace_accs_Rollout = []\n",
    "        \n",
    "        instance_degradation_probs_LRP = []\n",
    "        instance_degradation_accs_LRP = []\n",
    "        instance_replace_probs_LRP = []\n",
    "        instance_replace_accs_LRP = []\n",
    "\n",
    "        for num in trunc_words_num[1:]: #exclude 0\n",
    "            \n",
    "            # TransCAM\n",
    "            truncated_text_ids_TransCAM, _, _ = truncate_words(sorted_idx_TransCAM, text_words, text_ids, \n",
    "                                                                                        num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_TransCAM, _ = replace_words(sorted_idx_TransCAM, text_words, text_ids, num, mask, mask_id)\n",
    "           \n",
    "            trunc_class_TransCAM, trunc_prob_TransCAM = predict(model, truncated_text_ids_TransCAM, target, seg_ids=seg_ids)\n",
    "            rep_class_TransCAM, rep_prob_TransCAM = predict(model, replaced_text_ids_TransCAM, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_TransCAM.append(trunc_prob_TransCAM)\n",
    "            instance_degradation_accs_TransCAM.append(trunc_class_TransCAM==target)\n",
    "            \n",
    "            instance_replace_probs_TransCAM.append(rep_prob_TransCAM)\n",
    "            instance_replace_accs_TransCAM.append(rep_class_TransCAM==target)\n",
    "            \n",
    "            # Rawatt\n",
    "            truncated_text_ids_Rawatt, _, _ = truncate_words(sorted_idx_Rawatt, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_Rawatt, _ = replace_words(sorted_idx_Rawatt, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            \n",
    "            trunc_class_Rawatt, trunc_prob_Rawatt = predict(model, truncated_text_ids_Rawatt, target, seg_ids=seg_ids)\n",
    "            rep_class_Rawatt, rep_prob_Rawatt = predict(model, replaced_text_ids_Rawatt, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_Rawatt.append(trunc_prob_Rawatt)\n",
    "            instance_degradation_accs_Rawatt.append(trunc_class_Rawatt==target)\n",
    "            \n",
    "            instance_replace_probs_Rawatt.append(rep_prob_Rawatt)\n",
    "            instance_replace_accs_Rawatt.append(rep_class_Rawatt==target)\n",
    "            \n",
    "            # PartialLRP\n",
    "            truncated_text_ids_PartialLRP, _, _ = truncate_words(sorted_idx_PartialLRP, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_PartialLRP, _ = replace_words(sorted_idx_PartialLRP, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            trunc_class_PartialLRP, trunc_prob_PartialLRP = predict(model, truncated_text_ids_PartialLRP, target, seg_ids=seg_ids)\n",
    "            rep_class_PartialLRP, rep_prob_PartialLRP = predict(model, replaced_text_ids_PartialLRP, target, seg_ids=seg_ids)\n",
    "            \n",
    "            instance_degradation_probs_PartialLRP.append(trunc_prob_PartialLRP)\n",
    "            instance_degradation_accs_PartialLRP.append(trunc_class_PartialLRP==target)\n",
    "            \n",
    "            instance_replace_probs_PartialLRP.append(rep_prob_PartialLRP)\n",
    "            instance_replace_accs_PartialLRP.append(rep_class_PartialLRP==target)\n",
    "            \n",
    "            # Rollout\n",
    "            truncated_text_ids_Rollout, _, _ = truncate_words(sorted_idx_Rollout, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_Rollout, _ = replace_words(sorted_idx_Rollout, text_words, text_ids, num, mask, mask_id)\n",
    "            \n",
    "            trunc_class_Rollout, trunc_prob_Rollout = predict(model, truncated_text_ids_Rollout, target, seg_ids=seg_ids)\n",
    "            rep_class_Rollout, rep_prob_Rollout = predict(model, replaced_text_ids_Rollout, target, seg_ids=seg_ids)\n",
    "            \n",
    "            instance_degradation_probs_Rollout.append(trunc_prob_Rollout)\n",
    "            instance_degradation_accs_Rollout.append(trunc_class_Rollout==target)\n",
    "            \n",
    "            instance_replace_probs_Rollout.append(rep_prob_Rollout)\n",
    "            instance_replace_accs_Rollout.append(rep_class_Rollout==target)\n",
    "            \n",
    "            # LRP\n",
    "            truncated_text_ids_LRP, _, _ = truncate_words(sorted_idx_LRP, text_words, text_ids, \n",
    "                                                                                       num, seg_ids=seg_ids)\n",
    "            replaced_text_ids_LRP, _ = replace_words(sorted_idx_LRP, text_words, text_ids, num, mask, mask_id)\n",
    "                \n",
    "            trunc_class_LRP, trunc_prob_LRP = predict(model, truncated_text_ids_LRP, target, seg_ids=seg_ids)\n",
    "            rep_class_LRP, rep_prob_LRP = predict(model, replaced_text_ids_LRP, target, seg_ids=seg_ids)\n",
    "\n",
    "            instance_degradation_probs_LRP.append(trunc_prob_LRP)\n",
    "            instance_degradation_accs_LRP.append(trunc_class_LRP==target)\n",
    "            \n",
    "            instance_replace_probs_LRP.append(rep_prob_LRP)\n",
    "            instance_replace_accs_LRP.append(rep_class_LRP==target)\n",
    "\n",
    "        original_probs.append(original_prob)\n",
    "        original_accs.append(original_class==target)\n",
    "        \n",
    "        degradation_probs_TransCAM.append(instance_degradation_probs_TransCAM)\n",
    "        degradation_accs_TransCAM.append(instance_degradation_accs_TransCAM)\n",
    "        del_probs_TransCAM.append(instance_replace_probs_TransCAM)\n",
    "        del_accs_TransCAM.append(instance_replace_accs_TransCAM)\n",
    "        \n",
    "        \n",
    "        degradation_probs_Rawatt.append(instance_degradation_probs_Rawatt)\n",
    "        degradation_accs_Rawatt.append(instance_degradation_accs_Rawatt)\n",
    "        del_probs_Rawatt.append(instance_replace_probs_Rawatt)\n",
    "        del_accs_Rawatt.append(instance_replace_accs_Rawatt)\n",
    "        \n",
    "        degradation_probs_PartialLRP.append(instance_degradation_probs_PartialLRP)\n",
    "        degradation_accs_PartialLRP.append(instance_degradation_accs_PartialLRP)\n",
    "        del_probs_PartialLRP.append(instance_replace_probs_PartialLRP)\n",
    "        del_accs_PartialLRP.append(instance_replace_accs_PartialLRP)\n",
    "        \n",
    "        degradation_probs_Rollout.append(instance_degradation_probs_Rollout)\n",
    "        degradation_accs_Rollout.append(instance_degradation_accs_Rollout)\n",
    "        del_probs_Rollout.append(instance_replace_probs_Rollout)\n",
    "        del_accs_Rollout.append(instance_replace_accs_Rollout)\n",
    "        \n",
    "        degradation_probs_LRP.append(instance_degradation_probs_LRP)\n",
    "        degradation_accs_LRP.append(instance_degradation_accs_LRP)\n",
    "        del_probs_LRP.append(instance_replace_probs_LRP)\n",
    "        del_accs_LRP.append(instance_replace_accs_LRP)\n",
    "        \n",
    "        \n",
    "        kendaltau_TransCAM = cal_kendaltau(attribution_TransCAM,attribution_TransCAM_F)\n",
    "        kendaltaus_TransCAM.append(kendaltau_TransCAM)      \n",
    "        \n",
    "        kendaltau_Rawatt = cal_kendaltau(attribution_Rawatt,attribution_Rawatt_F)\n",
    "        kendaltaus_Rawatt.append(kendaltau_Rawatt)      \n",
    "        \n",
    "        kendaltau_PartialLRP = cal_kendaltau(attribution_PartialLRP,attribution_PartialLRP_F)\n",
    "        kendaltaus_PartialLRP.append(kendaltau_PartialLRP)      \n",
    "        \n",
    "        kendaltau_Rollout = cal_kendaltau(attribution_Rollout,attribution_Rollout_F)\n",
    "        kendaltaus_Rollout.append(kendaltau_Rollout)      \n",
    "        \n",
    "        kendaltau_LRP = cal_kendaltau(attribution_LRP,attribution_LRP_F)\n",
    "        kendaltaus_LRP.append(kendaltau_LRP)      \n",
    "    \n",
    "    # get aopc score\n",
    "    aopc_TransCAM = cal_aopc(original_probs,degradation_probs_TransCAM)\n",
    "    aopc_Rawatt = cal_aopc(original_probs,degradation_probs_Rawatt)\n",
    "    aopc_PartialLRP = cal_aopc(original_probs,degradation_probs_PartialLRP)\n",
    "    aopc_Rollout = cal_aopc(original_probs,degradation_probs_Rollout)\n",
    "    aopc_LRP = cal_aopc(original_probs,degradation_probs_LRP)\n",
    "    \n",
    "    aopc_TransCAM_del = cal_aopc(original_probs,del_probs_TransCAM)\n",
    "    aopc_Rawatt_del = cal_aopc(original_probs,del_probs_Rawatt)\n",
    "    aopc_PartialLRP_del = cal_aopc(original_probs,del_probs_PartialLRP)\n",
    "    aopc_Rollout_del = cal_aopc(original_probs,del_probs_Rollout)\n",
    "    aopc_LRP_del = cal_aopc(original_probs,del_probs_LRP)\n",
    "        \n",
    "        \n",
    "    logodds_TransCAM = cal_logodds(original_probs,degradation_probs_TransCAM)\n",
    "    logodds_Rawatt = cal_logodds(original_probs,degradation_probs_Rawatt)\n",
    "    logodds_PartialLRP = cal_logodds(original_probs,degradation_probs_PartialLRP)\n",
    "    logodds_Rollout = cal_logodds(original_probs,degradation_probs_Rollout)\n",
    "    logodds_LRP = cal_logodds(original_probs,degradation_probs_LRP)\n",
    "    \n",
    "    logodds_TransCAM_del = cal_logodds(original_probs,del_probs_TransCAM)\n",
    "    logodds_Rawatt_del = cal_logodds(original_probs,del_probs_Rawatt)\n",
    "    logodds_PartialLRP_del = cal_logodds(original_probs,del_probs_PartialLRP)\n",
    "    logodds_Rollout_del = cal_logodds(original_probs,del_probs_Rollout)\n",
    "    logodds_LRP_del = cal_logodds(original_probs,del_probs_LRP)\n",
    "        \n",
    "            \n",
    "    # get kendaltau score    \n",
    "    k_TransCAM = np.mean(kendaltaus_TransCAM)\n",
    "    k_Rawatt = np.mean(kendaltaus_Rawatt)\n",
    "    k_PartialLRP = np.mean(kendaltaus_PartialLRP)\n",
    "    k_Rollout = np.mean(kendaltaus_Rollout)\n",
    "    k_LRP = np.mean(kendaltaus_LRP)\n",
    "        \n",
    "    return (aopc_TransCAM, aopc_Rawatt, aopc_PartialLRP, aopc_Rollout, aopc_LRP,\n",
    "            aopc_TransCAM_del, aopc_Rawatt_del, aopc_PartialLRP_del, aopc_Rollout_del, aopc_LRP_del,\n",
    "            k_TransCAM, k_Rawatt, k_PartialLRP, k_Rollout, k_LRP,\n",
    "            logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP,\n",
    "            logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36105a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the explanations generator\n",
    "explanations = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12ceb15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_num = 500\n",
    "to_test = np.array(tokenized_mnli['validation_matched'])\n",
    "# to_test_idx = np.random.choice(len(tokenized_mnli['validation_matched']), test_num, replace=False)\n",
    "# to_test = to_test[to_test_idx]\n",
    "# len(to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01fed0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testinstant0of9815\n",
      "--- 0.00014209747314453125 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anwbw/.local/lib/python3.9/site-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "(aopc_TransCAM, aopc_Rawatt, aopc_PartialLRP, aopc_Rollout, aopc_LRP,\n",
    " aopc_TransCAM_del, aopc_Rawatt_del, aopc_PartialLRP_del, aopc_Rollout_del, aopc_LRP_del,\n",
    " k_TransCAM, k_Rawatt, k_PartialLRP, k_Rollout, k_LRP,\n",
    " logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP,\n",
    " logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del) = test(model, explanations, to_test, degrade_step = 10, seg_ids=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU information\n",
    "import GPUtil\n",
    "from tabulate import tabulate\n",
    "print(\"=\"*40, \"GPU Details\", \"=\"*40)\n",
    "gpus = GPUtil.getGPUs()\n",
    "list_gpus = []\n",
    "for gpu in gpus:\n",
    "    # get the GPU id\n",
    "    gpu_id = gpu.id\n",
    "    # name of GPU\n",
    "    gpu_name = gpu.name\n",
    "    # get % percentage of GPU usage of that GPU\n",
    "    gpu_load = f\"{gpu.load*100}%\"\n",
    "    # get free memory in MB format\n",
    "    gpu_free_memory = f\"{gpu.memoryFree}MB\"\n",
    "    # get used memory\n",
    "    gpu_used_memory = f\"{gpu.memoryUsed}MB\"\n",
    "    # get total memory\n",
    "    gpu_total_memory = f\"{gpu.memoryTotal}MB\"\n",
    "    # get GPU temperature in Celsius\n",
    "    gpu_temperature = f\"{gpu.temperature} Â°C\"\n",
    "    gpu_uuid = gpu.uuid\n",
    "    list_gpus.append((\n",
    "        gpu_id, gpu_name, gpu_load, gpu_free_memory, gpu_used_memory,\n",
    "        gpu_total_memory, gpu_temperature, gpu_uuid\n",
    "    ))\n",
    "\n",
    "print(tabulate(list_gpus, headers=(\"id\", \"name\", \"load\", \"free memory\", \"used memory\", \"total memory\",\n",
    "                                   \"temperature\", \"uuid\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7c85b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(aopc_TransCAM,aopc_Rawatt,aopc_PartialLRP,aopc_Rollout,aopc_LRP)\n",
    "print(aopc_TransCAM_del,aopc_Rawatt_del,aopc_PartialLRP_del,aopc_Rollout_del,aopc_LRP_del)\n",
    "print(k_TransCAM,k_Rawatt,k_PartialLRP,k_Rollout,k_LRP)\n",
    "print(logodds_TransCAM, logodds_Rawatt, logodds_PartialLRP, logodds_Rollout, logodds_LRP)\n",
    "print(logodds_TransCAM_del, logodds_Rawatt_del, logodds_PartialLRP_del, logodds_Rollout_del, logodds_LRP_del)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c21eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [10,20,30,40,50,60,70,80,90]\n",
    "#AOPC masked values\n",
    "plt.plot(x, aopc_TransCAM, label=\"TransCAM\")\n",
    "plt.plot(x, aopc_Rawatt, label =\"Rawatt\")\n",
    "plt.plot(x, aopc_LRP, label = \"LRP\")\n",
    "plt.plot(x, aopc_PartialLRP, label=\"PartialLRP\")\n",
    "plt.plot(x, aopc_Rollout, label=\"Rollout\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"AOPC-Score\")\n",
    "plt.legend()\n",
    "plt.savefig(\"AOPC.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd714253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AOPC delted values\n",
    "plt.plot(x, aopc_TransCAM_del, label=\"TransCAM\")\n",
    "plt.plot(x, aopc_Rawatt_del, label =\"Rawatt\")\n",
    "plt.plot(x, aopc_LRP_del, label = \"LRP\")\n",
    "plt.plot(x, aopc_PartialLRP_del, label=\"PartialLRP\")\n",
    "plt.plot(x, aopc_Rollout_del, label=\"Rollout\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"AOPC-Score\")\n",
    "plt.legend()\n",
    "plt.savefig(\"AOPC_del.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64237d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lodds masked values\n",
    "plt.plot(x, logodds_TransCAM, label=\"TransCAM\")\n",
    "plt.plot(x, logodds_Rawatt, label =\"Rawatt\")\n",
    "plt.plot(x, logodds_LRP, label = \"LRP\")\n",
    "plt.plot(x, logodds_PartialLRP, label=\"PartialLRP\")\n",
    "plt.plot(x, logodds_Rollout, label=\"Rollout\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"LogOdds-Score\")\n",
    "plt.legend()\n",
    "plt.savefig(\"logodds.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cccdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lodds del values\n",
    "plt.plot(x, logodds_TransCAM_del, label=\"TransCAM\")\n",
    "plt.plot(x, logodds_Rawatt_del, label =\"Rawatt\")\n",
    "plt.plot(x, logodds_LRP_del, label = \"LRP\")\n",
    "plt.plot(x, logodds_PartialLRP_del, label=\"PartialLRP\")\n",
    "plt.plot(x, logodds_Rollout_del, label=\"Rollout\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"LogOdds-Score\")\n",
    "plt.legend()\n",
    "plt.savefig(\"logodds_del.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d29d56f",
   "metadata": {},
   "source": [
    "# Single Example Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aa56044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expln_norm(expln):\n",
    "    expln = (expln - expln.min()) / (expln.max()- expln.min())\n",
    "    return expln\n",
    "\n",
    "def show_text_attr(expln,str_list,is_relu = True):\n",
    "    if is_relu:\n",
    "        rgb = lambda x: '0,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: max(x, 0)* 10\n",
    "    else:\n",
    "        rgb = lambda x: '255,0,0' if x < 0 else '0,255,0'\n",
    "        alpha = lambda x: x * -5 if x < 0 else x * 5\n",
    "    attrs = list(expln)\n",
    "    subwords = str_list\n",
    "    \n",
    "    token_marks = [\n",
    "        f'<mark style=\"background-color:rgba({rgb(attr)},{alpha(attr)})\">{token}</mark>'\n",
    "        for token, attr in zip(subwords, attrs)\n",
    "    ]\n",
    "    \n",
    "    display(HTML('<p>' + ' '.join(token_marks) + '</p>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "513e5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids, attention_mask, text_words, label = preprocess_sample(tokenized_mnli,index=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8693c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the explanations generator\n",
    "explanations = Generator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4c37cf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TransCAM_expln, LRP_expln, PartialLRP_expln, FullLRP_expln, Att_expln, Rollout_expln, Att_Gradcam_expln = \\\n",
    "        # generate_explns(explanations, input_ids, attention_mask, start_layer=0, true_class = label, is_true = True) \n",
    "TransCAM_expln, LRP_expln, PartialLRP_expln, Att_expln, Rollout_expln = \\\n",
    "       generate_explns(explanations, input_ids, attention_mask, start_layer=0, true_class = label, is_true = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ab1f539a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.0468820184469223)\">you</mark> <mark style=\"background-color:rgba(255,0,0,0.09953304380178452)\">and</mark> <mark style=\"background-color:rgba(0,255,0,0.003207998815923929)\">your</mark> <mark style=\"background-color:rgba(0,255,0,0.11359000205993652)\">friends</mark> <mark style=\"background-color:rgba(255,0,0,0.021085500717163086)\">are</mark> <mark style=\"background-color:rgba(255,0,0,0.27380064129829407)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.33982786536216736)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.10419975966215134)\">here</mark> <mark style=\"background-color:rgba(255,0,0,0.14035068452358246)\">,</mark> <mark style=\"background-color:rgba(255,0,0,0.09087537229061127)\">said</mark> <mark style=\"background-color:rgba(255,0,0,0.22080770134925842)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,0.6853544116020203)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,0.041720498353242874)\">severn</mark> <mark style=\"background-color:rgba(255,0,0,0.004985099658370018)\">said</mark> <mark style=\"background-color:rgba(0,255,0,0.004585662391036749)\">the</mark> <mark style=\"background-color:rgba(255,0,0,0.20457348227500916)\">people</mark> <mark style=\"background-color:rgba(0,255,0,0.14572805166244507)\">were</mark> <mark style=\"background-color:rgba(255,0,0,0.43065789341926575)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.3891936242580414)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.00025078828912228346)\">there</mark> <mark style=\"background-color:rgba(255,0,0,0.4097570478916168)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TransCAM_expln = expln_norm(TransCAM_expln)\n",
    "show_text_attr(TransCAM_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38658983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.23058933019638062)\">you</mark> <mark style=\"background-color:rgba(0,255,0,0.2381700873374939)\">and</mark> <mark style=\"background-color:rgba(0,255,0,0.3045923709869385)\">your</mark> <mark style=\"background-color:rgba(0,255,0,0.36217010021209717)\">friends</mark> <mark style=\"background-color:rgba(0,255,0,0.28604716062545776)\">are</mark> <mark style=\"background-color:rgba(0,255,0,0.37323877215385437)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.23434683680534363)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.1936296820640564)\">here</mark> <mark style=\"background-color:rgba(0,255,0,0.08108212053775787)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.0991029292345047)\">said</mark> <mark style=\"background-color:rgba(0,255,0,0.1582164764404297)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,0.3945159614086151)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,0.09152929484844208)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,0.2077145129442215)\">said</mark> <mark style=\"background-color:rgba(0,255,0,0.3169253170490265)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.23712310194969177)\">people</mark> <mark style=\"background-color:rgba(0,255,0,0.2994172275066376)\">were</mark> <mark style=\"background-color:rgba(0,255,0,0.3246826231479645)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.16132846474647522)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.15394827723503113)\">there</mark> <mark style=\"background-color:rgba(0,255,0,0.25162962079048157)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LRP_expln = expln_norm(LRP_expln)\n",
    "show_text_attr(LRP_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ad9fe4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,2.961775779724121)\">you</mark> <mark style=\"background-color:rgba(0,255,0,3.1271278858184814)\">and</mark> <mark style=\"background-color:rgba(0,255,0,4.041153907775879)\">your</mark> <mark style=\"background-color:rgba(0,255,0,4.544245719909668)\">friends</mark> <mark style=\"background-color:rgba(0,255,0,3.8759002685546875)\">are</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">not</mark> <mark style=\"background-color:rgba(0,255,0,3.1050186157226562)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,2.4306528568267822)\">here</mark> <mark style=\"background-color:rgba(0,255,0,0.667578935623169)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.8626386523246765)\">said</mark> <mark style=\"background-color:rgba(0,255,0,1.1204502582550049)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,3.5264265537261963)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,0.7270329594612122)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,2.447462558746338)\">said</mark> <mark style=\"background-color:rgba(0,255,0,3.935497760772705)\">the</mark> <mark style=\"background-color:rgba(0,255,0,3.1916401386260986)\">people</mark> <mark style=\"background-color:rgba(0,255,0,4.024518966674805)\">were</mark> <mark style=\"background-color:rgba(0,255,0,4.360008716583252)\">not</mark> <mark style=\"background-color:rgba(0,255,0,2.1630821228027344)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,1.8753756284713745)\">there</mark> <mark style=\"background-color:rgba(0,255,0,2.749009370803833)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PartialLRP_expln = expln_norm(PartialLRP_expln)\n",
    "show_text_attr(PartialLRP_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bb8055e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,0.20164422690868378)\">you</mark> <mark style=\"background-color:rgba(0,255,0,0.21890121698379517)\">and</mark> <mark style=\"background-color:rgba(0,255,0,0.19048964977264404)\">your</mark> <mark style=\"background-color:rgba(0,255,0,0.2492472380399704)\">friends</mark> <mark style=\"background-color:rgba(0,255,0,0.22862204909324646)\">are</mark> <mark style=\"background-color:rgba(0,255,0,0.20587952435016632)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.276088684797287)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.2491435408592224)\">here</mark> <mark style=\"background-color:rgba(0,255,0,0.2923462390899658)\">,</mark> <mark style=\"background-color:rgba(0,255,0,0.3083673417568207)\">said</mark> <mark style=\"background-color:rgba(0,255,0,0.2324800342321396)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,0.3713010251522064)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,0.20632421970367432)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,0.2728576064109802)\">said</mark> <mark style=\"background-color:rgba(0,255,0,0.1883271336555481)\">the</mark> <mark style=\"background-color:rgba(0,255,0,0.1959867775440216)\">people</mark> <mark style=\"background-color:rgba(0,255,0,0.20281805098056793)\">were</mark> <mark style=\"background-color:rgba(0,255,0,0.181955024600029)\">not</mark> <mark style=\"background-color:rgba(0,255,0,0.23943482339382172)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,0.19285935163497925)\">there</mark> <mark style=\"background-color:rgba(0,255,0,0.29370641708374023)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Att_expln = expln_norm(Att_expln)\n",
    "show_text_attr(Att_expln,text_words,is_relu = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9982ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><mark style=\"background-color:rgba(0,255,0,0.0)\">[CLS]</mark> <mark style=\"background-color:rgba(0,255,0,2.3205347061157227)\">you</mark> <mark style=\"background-color:rgba(0,255,0,2.6373634338378906)\">and</mark> <mark style=\"background-color:rgba(0,255,0,2.2894461154937744)\">your</mark> <mark style=\"background-color:rgba(0,255,0,2.873426675796509)\">friends</mark> <mark style=\"background-color:rgba(0,255,0,2.5236189365386963)\">are</mark> <mark style=\"background-color:rgba(0,255,0,3.0973923206329346)\">not</mark> <mark style=\"background-color:rgba(0,255,0,2.5007519721984863)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,1.8261617422103882)\">here</mark> <mark style=\"background-color:rgba(0,255,0,1.1884262561798096)\">,</mark> <mark style=\"background-color:rgba(0,255,0,1.6144670248031616)\">said</mark> <mark style=\"background-color:rgba(0,255,0,1.318505883216858)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,5.0)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark> <mark style=\"background-color:rgba(0,255,0,0.746228039264679)\">severn</mark> <mark style=\"background-color:rgba(0,255,0,1.8209354877471924)\">said</mark> <mark style=\"background-color:rgba(0,255,0,2.250791311264038)\">the</mark> <mark style=\"background-color:rgba(0,255,0,2.0980677604675293)\">people</mark> <mark style=\"background-color:rgba(0,255,0,2.158541440963745)\">were</mark> <mark style=\"background-color:rgba(0,255,0,2.52248477935791)\">not</mark> <mark style=\"background-color:rgba(0,255,0,2.0588788986206055)\">welcome</mark> <mark style=\"background-color:rgba(0,255,0,1.9880117177963257)\">there</mark> <mark style=\"background-color:rgba(0,255,0,1.0152788162231445)\">.</mark> <mark style=\"background-color:rgba(0,255,0,0.0)\">[SEP]</mark></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Rollout_expln = expln_norm(Rollout_expln)\n",
    "show_text_attr(Rollout_expln,text_words,is_relu = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
